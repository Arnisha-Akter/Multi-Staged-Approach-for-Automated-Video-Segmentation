{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arnisha-Akter/Multi-Staged-Approach-for-Automated-Video-Segmentation/blob/main/(All_models_%26_test)_ASR_Whisper%2C_Bn_Clustering_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSJ1FMD3iRgK"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FvS6KqMhTmr"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "import csv\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8FYlQtpOBcK",
        "outputId": "69c59139-aad8-42ec-bda9-4d099aa2394f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7o3zY0kNk3G"
      },
      "outputs": [],
      "source": [
        "from nltk.translate.meteor_score import single_meteor_score\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DR0umq_eOZSW"
      },
      "outputs": [],
      "source": [
        "def meteor_score(ref_sentence, cand_sentence):\n",
        "  ref_tokens = word_tokenize(ref_sentence.lower())\n",
        "  cand_tokens = word_tokenize(cand_sentence.lower())\n",
        "\n",
        "  # Remove stopwords and lemmatize tokens\n",
        "  stop_words = set(stopwords.words('bengali'))\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  ref_tokens = [lemmatizer.lemmatize(token) for token in ref_tokens if token not in stop_words]\n",
        "  cand_tokens = [lemmatizer.lemmatize(token) for token in cand_tokens if token not in stop_words]\n",
        "\n",
        "  return single_meteor_score(ref_tokens, cand_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtroRjjGgp-Z",
        "outputId": "b2afcf17-c046-48bb-a316-f7cd6600840c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfYmT33MNrTR"
      },
      "source": [
        "# **ASR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twpWRVGuiLC7"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"anuragshas/whisper-small-bn\"\n",
        "lang = \"bn\"\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "pipe = pipeline(\n",
        "    task=\"automatic-speech-recognition\",\n",
        "    model=MODEL_NAME,\n",
        "    chunk_length_s=30,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "pipe.model.config.forced_decoder_ids = pipe.tokenizer.get_decoder_prompt_ids(language=lang, task=\"transcribe\")\n",
        "\n",
        "# file_path = \"/content/drive/MyDrive/fahad.wav\"\n",
        "# text = pipe(file_path)[\"text\"]\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/FYDP II/videos/Audio Chunks.csv\")\n",
        "\n",
        "wav_dir = '/content/drive/MyDrive/FYDP II/videos/wav'\n",
        "for i, d in df.iterrows():\n",
        "  audio, textRef = os.path.join(wav_dir, d['id']), d['text']\n",
        "  print(f\"audio path: {audio}\")\n",
        "  # print(textRef)\n",
        "\n",
        "  # Load the audio file using torchaudio\n",
        "  file_name = os.path.basename(audio)\n",
        "  # print(file_name)\n",
        "\n",
        "  audiofile, sample_rate = torchaudio.load(\"/content/drive/MyDrive/FYDP II/videos/wav/\" + file_name)\n",
        "  # Resample the audio to match the expected sample rate of the model\n",
        "  # if sample_rate != 16000:\n",
        "  #     resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
        "  #     audio = resampler(audio)\n",
        "  #     sample_rate = 16000\n",
        "\n",
        "  textPre = pipe(\"/content/drive/MyDrive/FYDP II/videos/wav/\" + file_name)[\"text\"]\n",
        "  print(\"Reference: \", textRef)\n",
        "  print(\"File No: \", i+1,\"Predicted: \", textPre)\n",
        "\n",
        "  # Create a new column with the appended string\n",
        "  df.at[i, 'predicted'] = textPre\n",
        "\n",
        "  # Write the updated dataframe to a new CSV file\n",
        "  df.to_csv(\"/content/drive/MyDrive/FYDP II/videos/Audio Chunks.csv\", index=False)\n",
        "\n",
        "  # # Calculate METEOR SCORE\n",
        "  # meteor = meteor_score(textRef, textPre)\n",
        "  # print(\"METEOR score:\", meteor)\n",
        "\n",
        "  # # Create a score with the METEOR SCORE\n",
        "  # df.at[i, 'score'] = meteor\n",
        "\n",
        "  # # Write the updated dataframe to a new CSV file\n",
        "  # df.to_csv('/content/drive/MyDrive/FYDP II/videos/Video Chunks.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YS1mmveyCi-"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"anuragshas/whisper-large-v2-bn\"\n",
        "lang = \"bn\"\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "pipe = pipeline(\n",
        "    task=\"automatic-speech-recognition\",\n",
        "    model=MODEL_NAME,\n",
        "    chunk_length_s=30,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "pipe.model.config.forced_decoder_ids = pipe.tokenizer.get_decoder_prompt_ids(language=lang, task=\"transcribe\")\n",
        "\n",
        "# file_path = \"/content/drive/MyDrive/fahad.wav\"\n",
        "# text = pipe(file_path)[\"text\"]\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/FYDP II/videos/Audio Chunks.csv\")\n",
        "\n",
        "wav_dir = '/content/drive/MyDrive/FYDP II/videos/wav'\n",
        "for i, d in df.iterrows():\n",
        "  audio, textRef = os.path.join(wav_dir, d['id']), d['text']\n",
        "  print(f\"audio path: {audio}\")\n",
        "  # print(textRef)\n",
        "\n",
        "  # Load the audio file using torchaudio\n",
        "  file_name = os.path.basename(audio)\n",
        "  # print(file_name)\n",
        "\n",
        "  audiofile, sample_rate = torchaudio.load(\"/content/drive/MyDrive/FYDP II/videos/wav/\" + file_name)\n",
        "  # Resample the audio to match the expected sample rate of the model\n",
        "  # if sample_rate != 16000:\n",
        "  #     resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
        "  #     audio = resampler(audio)\n",
        "  #     sample_rate = 16000\n",
        "\n",
        "  textPre = pipe(\"/content/drive/MyDrive/FYDP II/videos/wav/\" + file_name)[\"text\"]\n",
        "  print(\"Reference: \", textRef)\n",
        "  print(\"File No: \", i+1,\"Predicted: \", textPre)\n",
        "\n",
        "  # Create a new column with the appended string\n",
        "  df.at[i, 'predicted-whisper-lg'] = textPre\n",
        "\n",
        "  # Write the updated dataframe to a new CSV file\n",
        "  df.to_csv(\"/content/drive/MyDrive/FYDP II/videos/Audio Chunks.csv\", index=False)\n",
        "\n",
        "  # # Calculate METEOR SCORE\n",
        "  # meteor = meteor_score(textRef, textPre)\n",
        "  # print(\"METEOR score:\", meteor)\n",
        "\n",
        "  # # Create a score with the METEOR SCORE\n",
        "  # df.at[i, 'score'] = meteor\n",
        "\n",
        "  # # Write the updated dataframe to a new CSV file\n",
        "  # df.to_csv('/content/drive/MyDrive/FYDP II/videos/Video Chunks.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQmqx8ixEcyl"
      },
      "source": [
        "# **ASR FINAL TEST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keEbNTciEcjB"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"anuragshas/whisper-large-v2-bn\"\n",
        "lang = \"bn\"\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "pipe = pipeline(\n",
        "    task=\"automatic-speech-recognition\",\n",
        "    model=MODEL_NAME,\n",
        "    chunk_length_s=30,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "pipe.model.config.forced_decoder_ids = pipe.tokenizer.get_decoder_prompt_ids(language=lang, task=\"transcribe\")\n",
        "\n",
        "# file_path = \"/content/drive/MyDrive/fahad.wav\"\n",
        "# text = pipe(file_path)[\"text\"]\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/directory/audio/audio.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "972LGpJMINcn",
        "outputId": "0845a400-f8ea-4651-93d2-df5daa5b49da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "audio path: /content/drive/MyDrive/directory/audio/chunk_1.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File No:  1 Predicted:  ফ্রান্সকে হারিয়ে দুইহাজার পাশ বিশোকাপ জিতে নিল আর্জেন্টিনা।\n",
            "audio path: /content/drive/MyDrive/directory/audio/chunk_2.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File No:  2 Predicted:  এ বাড়ির ঘূর্ণী ঝড়ে আট বর্গ-কিলোমিটার আয়েতনের এই দ্বীপে দুই হাজারের বেশি ঘোরবাড়ি ও দোকানপাট ক্ষতিগ্রস্থ হয়েছে।\n",
            "audio path: /content/drive/MyDrive/directory/audio/chunk_3.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File No:  3 Predicted:  লিওনেল মেসির জন্ম আর্জেন্টিনার রোজারীয় শহরে।\n",
            "audio path: /content/drive/MyDrive/directory/audio/chunk_4.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File No:  4 Predicted:  দুঃহাজার দশের শেষ ফুটবল বিশ্বকাপ খেলেছিল ইতালি।\n",
            "audio path: /content/drive/MyDrive/directory/audio/chunk_5.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File No:  5 Predicted:  মেসি বিশ্বের সেরা ফুটবলারদের একজন।\n",
            "audio path: /content/drive/MyDrive/directory/audio/chunk_6.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File No:  6 Predicted:  ঘুনিজ্রর মুখোর আঘাত থেকে বাংলাদেশের মূল ভূখণ্ড মোটামুটি রক্ষা পেলে বিধ্বস্তু হয়েছে সাগর দ্বীপ সেনমার্ডিল।\n",
            "audio path: /content/drive/MyDrive/directory/audio/chunk_7.wav\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File No:  7 Predicted:  মেসিকে আবারও দেখা যেতে পারে বার্সেলোনার জার্জিতে।\n"
          ]
        }
      ],
      "source": [
        "wav_dir = '/content/drive/MyDrive/directory/audio'\n",
        "for i, d in df.iterrows():\n",
        "  audio = os.path.join(wav_dir, d['chunk_no'])\n",
        "  print(f\"audio path: {audio}\")\n",
        "\n",
        "  # Load the audio file using torchaudio\n",
        "  file_name = os.path.basename(audio)\n",
        "  # print(file_name)\n",
        "\n",
        "  audiofile, sample_rate = torchaudio.load(\"/content/drive/MyDrive/directory/audio/\" + file_name)\n",
        "  # Resample the audio to match the expected sample rate of the model\n",
        "  # if sample_rate != 16000:\n",
        "  #     resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
        "  #     audio = resampler(audio)\n",
        "  #     sample_rate = 16000\n",
        "\n",
        "  textPre = pipe(\"/content/drive/MyDrive/directory/audio/\" + file_name)[\"text\"]\n",
        "  print(\"File No: \", i+1,\"Predicted: \", textPre)\n",
        "\n",
        "  # Create a new column with the appended string\n",
        "  df.at[i, 'predicted'] = textPre\n",
        "\n",
        "  # Write the updated dataframe to a new CSV file\n",
        "  df.to_csv(\"/content/drive/MyDrive/directory/audio/audio.csv\", index=False)\n",
        "\n",
        "  # # Calculate METEOR SCORE\n",
        "  # meteor = meteor_score(textRef, textPre)\n",
        "  # print(\"METEOR score:\", meteor)\n",
        "\n",
        "  # # Create a score with the METEOR SCORE\n",
        "  # df.at[i, 'score'] = meteor\n",
        "\n",
        "  # # Write the updated dataframe to a new CSV file\n",
        "  # df.to_csv('/content/drive/MyDrive/FYDP II/videos/Video Chunks.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4T8KGFADKla3"
      },
      "outputs": [],
      "source": [
        "sentences = [\n",
        "    'ফ্রান্সকে হারিয়ে দুইহাজার পাশ বিশোকাপ জিতে নিল আর্জেন্টিনা।',\n",
        "    'এ বাড়ির ঘূর্ণী ঝড়ে আট বর্গ-কিলোমিটার আয়েতনের এই দ্বীপে দুই হাজারের বেশি ঘোরবাড়ি ও দোকানপাট ক্ষতিগ্রস্থ হয়েছে।',\n",
        "    'লিওনেল মেসির জন্ম আর্জেন্টিনার রোজারীয় শহরে।',\n",
        "    'দুঃহাজার দশের শেষ ফুটবল বিশ্বকাপ খেলেছিল ইতালি।',\n",
        "    'মেসি বিশ্বের সেরা ফুটবলারদের একজন।',\n",
        "    'ঘুনিজ্রর মুখোর আঘাত থেকে বাংলাদেশের মূল ভূখণ্ড মোটামুটি রক্ষা পেলে বিধ্বস্তু হয়েছে সাগর দ্বীপ সেনমার্ডিল।',\n",
        "    'মেসিকে আবারও দেখা যেতে পারে বার্সেলোনার জার্জিতে।'\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWI1IE-THh5p"
      },
      "source": [
        "# **Extra**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwrZkUO8b303"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers\n",
        "\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Load the pre-trained sentence transformer model\n",
        "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
        "\n",
        "# Example sentence embeddings\n",
        "sentences = [\n",
        "    'I love programming',\n",
        "    'Machine learning is fascinating',\n",
        "    'Data science is the future',\n",
        "    'Python is a versatile language',\n",
        "    'I enjoy coding challenges'\n",
        "]\n",
        "\n",
        "# Convert sentences to sentence embeddings\n",
        "sentence_embeddings = model.encode(sentences)\n",
        "\n",
        "# Apply k-means++ clustering\n",
        "num_clusters = 2  # Number of clusters\n",
        "kmeans = KMeans(n_clusters=num_clusters, init='k-means++', random_state=42)\n",
        "kmeans.fit(sentence_embeddings)\n",
        "\n",
        "# Get cluster assignments for each sentence\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "# Print the cluster assignments\n",
        "for sentence, label in zip(sentences, cluster_labels):\n",
        "    print(f'Sentence: {sentence} - Cluster: {label}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyE6R2LjkIfU",
        "outputId": "26a1d6d5-b5a7-483c-d2ae-fc146828a291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fasttext==0.9.2 in /usr/local/lib/python3.10/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (2.10.4)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (1.22.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: আমি প্রোগ্রামিং ভালবাসি - Cluster: 1\n",
            "Sentence: মেশিন লার্নিং মহান্ত্বপূর্ণ - Cluster: 0\n",
            "Sentence: ডাটা সায়েন্স ভবিষ্যতের কাছে - Cluster: 0\n",
            "Sentence: পাইথন একটি বহুমান্য ভাষা - Cluster: 0\n",
            "Sentence: আমি কোডিং চ্যালেঞ্জ ভোগ করি - Cluster: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext==0.9.2  # Install the FastText library\n",
        "\n",
        "import numpy as np\n",
        "import fasttext.util\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Download the Bengali FastText pre-trained model\n",
        "fasttext.util.download_model('bn', if_exists='ignore')\n",
        "\n",
        "# Load the Bengali FastText model\n",
        "model_path = 'cc.bn.300.bin'\n",
        "model = fasttext.load_model(model_path)\n",
        "\n",
        "# Example Bengali sentences\n",
        "sentences = [\n",
        "    'আমি প্রোগ্রামিং ভালবাসি',\n",
        "    'মেশিন লার্নিং মহান্ত্বপূর্ণ',\n",
        "    'ডাটা সায়েন্স ভবিষ্যতের কাছে',\n",
        "    'পাইথন একটি বহুমান্য ভাষা',\n",
        "    'আমি কোডিং চ্যালেঞ্জ ভোগ করি'\n",
        "]\n",
        "\n",
        "# Convert sentences to sentence embeddings using FastText word embeddings\n",
        "sentence_embeddings = []\n",
        "for sentence in sentences:\n",
        "    words = sentence.split()\n",
        "    word_embeddings = [model.get_word_vector(word) for word in words]\n",
        "    sentence_embedding = np.mean(word_embeddings, axis=0)\n",
        "    sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "sentence_embeddings = np.array(sentence_embeddings)\n",
        "\n",
        "# Apply k-means++ clustering\n",
        "num_clusters = 2  # Number of clusters\n",
        "kmeans = KMeans(n_clusters=num_clusters, init='k-means++', random_state=42)\n",
        "kmeans.fit(sentence_embeddings)\n",
        "\n",
        "# Get cluster assignments for each sentence\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "# Print the cluster assignments\n",
        "for sentence, label in zip(sentences, cluster_labels):\n",
        "    print(f'Sentence: {sentence} - Cluster: {label}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4-WoJIDBJGb"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qL41yrXVwm8E"
      },
      "source": [
        "# **CODE TEST 1 KMEANS++ -FT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da-PBU1naEkT",
        "outputId": "df4af1e7-b9af-4236-a3fa-822042e72bf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 sentence-transformers-3.0.1\n",
            "Collecting fasttext==0.9.2\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext==0.9.2)\n",
            "  Using cached pybind11-2.13.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (71.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext==0.9.2) (1.26.4)\n",
            "Using cached pybind11-2.13.1-py3-none-any.whl (238 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4232134 sha256=ba55a7b391a8e55c5218357326b61d74dc2b9b839d82578a14d5ae246d36a15a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers\n",
        "!pip install fasttext==0.9.2  # Install the FastText library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay-ILHWH_L_h",
        "outputId": "c7ffa979-e642-4aeb-a563-8cb52ab62082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ফ্রান্সকে হারিয়ে দুইহাজার পাশ বিশোকাপ জিতে নিল আর্জেন্টিনা।', 'এ বাড়ির ঘূর্ণী ঝড়ে আট বর্গ-কিলোমিটার আয়েতনের এই দ্বীপে দুই হাজারের বেশি ঘোরবাড়ি ও দোকানপাট ক্ষতিগ্রস্থ হয়েছে।', 'লিওনেল মেসির জন্ম আর্জেন্টিনার রোজারীয় শহরে।', 'দুঃহাজার দশের শেষ ফুটবল বিশ্বকাপ খেলেছিল ইতালি।', 'মেসি বিশ্বের সেরা ফুটবলারদের একজন।', 'ঘুনিজ্রর মুখোর আঘাত থেকে বাংলাদেশের মূল ভূখণ্ড মোটামুটি রক্ষা পেলে বিধ্বস্তু হয়েছে সাগর দ্বীপ সেনমার্ডিল।', 'মেসিকে আবারও দেখা যেতে পারে বার্সেলোনার জার্জিতে।']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Bangla dataset/Clustering/audio.csv'\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "column_name = 'text'\n",
        "\n",
        "sentences = []\n",
        "\n",
        "for i, d in df.iterrows():\n",
        "    textRef = d['text']\n",
        "    sentences.append(textRef)\n",
        "\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "import os\n",
        "\n",
        "# Create a training file with different but similar Bangla sentences\n",
        "train_sentences = [\n",
        "    \"রাজনৈতিক দলের নেতার বিরুদ্ধে দুর্নীতির অভিযোগ উঠেছে\",\n",
        "    \"শহরের কেন্দ্রস্থলে নতুন উদ্যান নির্মাণের সিদ্ধান্ত নিয়েছে সরকার\",\n",
        "    \"জাতীয় ফুটবল দলের অধিনায়ক পরবর্তী বিশ্বকাপে খেলবেন না\",\n",
        "    \"গবেষণায় দেখা গেছে, বায়ু দূষণের কারণে শহরে শ্বাসকষ্টের রোগী বেড়েছে\",\n",
        "    \"গত মাসে রপ্তানি আয় কমেছে, যা অর্থনীতির জন্য উদ্বেগের কারণ হয়ে দাঁড়িয়েছে\",\n",
        "    \"নতুন শিক্ষানীতি চালু হওয়ায় শিক্ষার্থীদের মধ্যে আগ্রহ বেড়েছে\",\n",
        "    \"জলবায়ু পরিবর্তনের কারণে দেশের দক্ষিণাঞ্চলে বন্যার ঝুঁকি বেড়েছে\",\n",
        "    \"স্বাস্থ্যসেবা খাতে নতুন প্রকল্প চালু করেছে সরকার\",\n",
        "    \"আন্তর্জাতিক চলচ্চিত্র উৎসবে বাংলাদেশি ছবি পুরস্কার পেয়েছে\",\n",
        "    \"দেশের প্রযুক্তি খাতে বিদেশি বিনিয়োগ বাড়ছে\"\n",
        "]\n",
        "\n",
        "# Create a directory for the model if it doesn't exist\n",
        "model_dir = \"fasttext_model\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Write sentences to a file\n",
        "train_file = os.path.join(model_dir, \"train.txt\")\n",
        "with open(train_file, 'w', encoding='utf-8') as f:\n",
        "    for sentence in train_sentences:\n",
        "        f.write(f\"__label__0 {sentence}\\n\")\n",
        "\n",
        "# Train the FastText model\n",
        "model = fasttext.train_unsupervised(train_file, model='skipgram')\n",
        "\n",
        "# Save the trained model\n",
        "model_path = os.path.join(model_dir, \"bangla_fasttext_model.bin\")\n",
        "model.save_model(model_path)\n",
        "\n",
        "print(f\"Model trained and saved at {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igO6YEQiU6l8",
        "outputId": "1e8fc096-2ecb-44fe-b0be-6bceaccdf4e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained and saved at fasttext_model/bangla_fasttext_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paaSIv9QoFsS",
        "outputId": "d1650606-071d-435a-c6a7-c9cc29564a37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.bn.300.bin.gz\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText model loaded successfully.\n",
            "Model saved successfully at /content/drive/MyDrive/model_name_fast_text.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions completed and saved to '/content/drive/MyDrive/Thesis Personal/Data set/output_file_FT_K2.csv'\n",
            "                                          Input Text  Label  Predicted Label  \\\n",
            "0  সম্প্রতি বিশ্ববিদ্যালয় শাখা ছাত্রলীগের সাধারণ...      0                1   \n",
            "1  এসব অভিযোগের ব্যাপারে ছাত্রলীগের কেন্দ্রীয় সং...      0                1   \n",
            "2  বিভিন্ন সময়ে শাখা ছাত্রলীগের একাধিক সহসভাপতির...      0                1   \n",
            "3  রাজধানীর পলাশী এলাকায় ফাস্টফুডের দোকানের এক কর...      0                1   \n",
            "4  নূর উদ্দিন আহমেদ ঢাকা বিশ্ববিদ্যালয় শাখা ছাত্র...      0                1   \n",
            "\n",
            "  Remarks                                            Metrics  \n",
            "0      No  Overall Accuracy: 12.50%\\nYes: 12.50%\\nNo: 87....  \n",
            "1      No  Precision: 7.50%\\nRecall: 12.50%\\nF1 Score: 9.37%  \n",
            "2      No                                                     \n",
            "3      No                                                     \n",
            "4      No                                                     \n",
            "Sentence: সম্প্রতি বিশ্ববিদ্যালয় শাখা ছাত্রলীগের সাধারণ সম্পাদকের বিরুদ্ধে মেডিকেল প্রশ্নপত্র ফাঁসের অভিযোগ উঠেছে - Cluster: 1\n",
            "Sentence: এসব অভিযোগের ব্যাপারে ছাত্রলীগের কেন্দ্রীয় সংসদের যুগ্ম সাধারণ সম্পাদক ও তদন্ত কমিটির সদস্য আবদুল্লাহ হীল প্রথম আলোকে বলেন, তাঁরা সব বিষয়ে তদন্ত করবেন - Cluster: 1\n",
            "Sentence: বিভিন্ন সময়ে শাখা ছাত্রলীগের একাধিক সহসভাপতির বিরুদ্ধে চাঁদাবাজি, মারধর এবং ছাত্রদলের সঙ্গে সংশ্লিষ্ট থাকার অভিযোগ উঠেছে - Cluster: 1\n",
            "Sentence: রাজধানীর পলাশী এলাকায় ফাস্টফুডের দোকানের এক কর্মচারীকে মারধরের অভিযোগ উঠেছে ঢাকা বিশ্ববিদ্যালয় শাখা ছাত্রলীগের এক নেতার বিরুদ্ধে - Cluster: 1\n",
            "Sentence: নূর উদ্দিন আহমেদ ঢাকা বিশ্ববিদ্যালয় শাখা ছাত্রলীগের সাধারণ সম্পাদক তানভীর হাসান সৈকতের অনুসারী হিসেবে পরিচিত - Cluster: 1\n",
            "Sentence: রাজধানীর মিরপুরের বোটানিক্যাল গার্ডেন, পুরান ঢাকার বলধা গার্ডেনসহ দেশের ছয়টি উদ্যান ও ইকোপার্কে প্রবেশমূল্য বাড়ানোর সিদ্ধান্তকে অন্যায্য ও অবিবেচনাপ্রসূত আখ্যায়িত করে তা কমানোর দাবি জানিয়েছে ইনস্টিটিউট ফর প্ল্যানিং অ্যান্ড ডেভেলপমেন্ট - Cluster: 0\n",
            "Sentence: ১১৯ মিনিটে বদলি মেরিনোর গোল, জার্মানির হৃদয় ভেঙে সেমিফাইনালে স্পেন - Cluster: 0\n",
            "Sentence: কোয়ার্টার ফাইনাল থেকে বিদায়ের মধ্যে দিয়ে জার্মান তারকা টনি ক্রুসের বর্ণাঢ্য ফুটবল ক্যারিয়ারেরও হতাশজনক সমাপ্তি ঘটল - Cluster: 1\n",
            "Sentence: নয়তো স্লোভেনিয়ার বিপক্ষে ১০৫ মিনিটে পেনাল্টি মিস করে কি আর শিশুদের মতো কাঁদেন - Cluster: 0\n",
            "Sentence: এখনো গোল করার প্রতিটি সুযোগ লুফে নিতে চান রোনালদো - Cluster: 0\n",
            "Sentence: তবে ইউরোর শেষ ষোলোয় পেনাল্টি মিস ও ফ্রি–কিকে একের পর এক সুযোগ হাতছাড়া করার কারণে বেশ সমালোচনার মুখে পড়েছেন রোনালদো - Cluster: 0\n",
            "Sentence: যে কারণে আজ ফ্রান্সের বিপক্ষে ম্যাচের আগে কোচ রবার্তো মার্তিনেজকেও বিষয়টি নিয়ে কথা বলতে হয়েছে - Cluster: 0\n",
            "Sentence: ক্যারিয়ারে এখন পর্যন্ত ফ্রি–কিক থেকে ৬৩টি গোল করেছেন আল নাসর তারকা - Cluster: 0\n",
            "Sentence: বাংলাদেশ উদ্বেগজনক মাত্রার দূষণ এবং পরিবেশগত স্বাস্থ্য ঝুঁকিতে রয়েছে যা তুলনামূলক বেশি ক্ষতি করছে দরিদ্র, পাঁচ বছরের কম শিশু, বয়স্ক এবং নারীদের, যা বিশ্বব্যাংকের এক নতুন প্রতিবেদনে বলা হয়েছে - Cluster: 0\n",
            "Sentence: বাংলাদেশের জন্য পরিবেশের ঝুঁকি মোকাবেলা একই সঙ্গে উন্নয়ন ও অর্থনৈতিক অগ্রাধিকার - Cluster: 1\n",
            "Sentence: পরিবেশ দূষণ শিশুদের ওপর মারাত্বক প্রভাব ফেলছে - Cluster: 1\n",
            "Sentence: বায়ু দূষণ নিয়ন্ত্রণে সময়মতো এবং জরুরি হস্তক্ষেপ, উন্নত পানি, স্যানিটেশন ও হাইজিন (ওয়াশ) এবং সীসা দূষণ নিয়ন্ত্রণ প্রতি বছর ১ লাখ ৩৩ হাজারের বেশি অকালমৃত্যু ঠেকাতে পারে - Cluster: 0\n",
            "Sentence: সবুজ বিদ্যুৎ উৎপাদনে বিনিয়োগ,রান্নায় সবুজ জ্বালানি ব্যবহার এবং শিল্প-কারখানা থেকে দূষণ রোধে কঠোর নিয়ন্ত্রণ বায়ু দূষণ কমাতে পারে - Cluster: 1\n",
            "Sentence: সদ্য বিদায়ী ২০২৩-২৪ অর্থবছরের প্রথম ১০ মাস ও এর আগের ২০২২-২৩ অর্থবছরের প্রথম ১০ মাস মিলিয়ে মোট ২০ মাসে ৯ হাজার ৩১৪ কোটি ডলারের রপ্তানির তথ্য দিয়েছিল রপ্তানি উন্নয়ন ব্যুরো (ইপিবি) - Cluster: 0\n",
            "Sentence: তবে বাংলাদেশ ব্যাংক এখন বলছে, ওই সময় রপ্তানি হয়েছে ৬ হাজার ৯৮০ কোটি ডলার। তার মানে ২৫ শতাংশ রপ্তানির তথ্য উধাও হয়ে গেছে - Cluster: 0\n",
            "Sentence: প্তানির হিসাব দেশের লেনদেন ভারসাম্য ও বৈদেশিক মুদ্রার বিনিময় হারে প্রভাব ফেলে - Cluster: 1\n",
            "Sentence: এদিকে পণ্য রপ্তানির ২ হাজার ৩৩৪ কোটি ডলারের হিসাব কোথায় গেল, সে বিষয়ে নিশ্চুপ আছেন ইপিবির কর্মকর্তারা - Cluster: 0\n",
            "Sentence: রপ্তানির প্রকৃত তথ্যের ভিত্তিতে কেন্দ্রীয় ব্যাংক গত বুধবার লেনদেন ভারসাম্যের হিসাব করেছে - Cluster: 0\n",
            "Sentence: রপ্তানি তথ্যের হিসাবে ওলটপালট হওয়ায় গত বছরের জুলাই থেকে চলতি বছরের এপ্রিল পর্যন্ত লেনদেন ভারসাম্যে ঘাটতি হয়েছে ৫৫৬ কোটি ডলার - Cluster: 0\n",
            "\n",
            "Predicted Label Distribution:\n",
            "Predicted Label\n",
            "0    14\n",
            "1    10\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Remarks Distribution:\n",
            "Remarks\n",
            "No     0.875\n",
            "Yes    0.125\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Accuracy: 12.50%\n",
            "Precision: 7.50%\n",
            "Recall: 12.50%\n",
            "F1 Score: 9.37%\n",
            "[1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "24\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import fasttext.util\n",
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Download and load the FastText model\n",
        "fasttext.util.download_model('bn', if_exists='ignore')\n",
        "model_path = 'cc.bn.300.bin'\n",
        "\n",
        "try:\n",
        "    model = fasttext.load_model(model_path)\n",
        "    print(\"FastText model loaded successfully.\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# Save the model\n",
        "save_path = '/content/drive/MyDrive/model_name_fast_text.pth'\n",
        "try:\n",
        "    model.save_model(save_path)\n",
        "    print(f\"Model saved successfully at {save_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving model: {e}\")\n",
        "\n",
        "# Read the CSV file\n",
        "input_file = \"/content/drive/MyDrive/Thesis Personal/Data set/Bangla Input topics.csv\"\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Extract sentences from the 'Input Text' column\n",
        "sentences = df['Input Text'].tolist()\n",
        "\n",
        "# Generate sentence embeddings\n",
        "sentence_embeddings = []\n",
        "for sentence in sentences:\n",
        "    words = str(sentence).split()\n",
        "    word_embeddings = [model.get_word_vector(word) for word in words]\n",
        "    sentence_embedding = np.mean(word_embeddings, axis=0)\n",
        "    sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "sentence_embeddings = np.array(sentence_embeddings)\n",
        "\n",
        "# Perform K-means clustering\n",
        "num_clusters = 2  # Number of clusters\n",
        "kmeans = KMeans(n_clusters=num_clusters, init='k-means++', random_state=42)\n",
        "kmeans.fit(sentence_embeddings)\n",
        "\n",
        "# Get cluster labels\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "# Add predicted labels to the DataFrame\n",
        "df['Predicted Label'] = cluster_labels\n",
        "\n",
        "# Add remarks column by comparing 'Label' and 'Predicted Label'\n",
        "df['Remarks'] = df.apply(lambda row: 'Yes' if row['Label'] == row['Predicted Label'] else 'No', axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (df['Remarks'] == 'Yes').mean()\n",
        "yes_percentage = (df['Remarks'] == 'Yes').mean()\n",
        "no_percentage = (df['Remarks'] == 'No').mean()\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(df['Label'], df['Predicted Label'], average='weighted')\n",
        "recall = recall_score(df['Label'], df['Predicted Label'], average='weighted')\n",
        "f1 = f1_score(df['Label'], df['Predicted Label'], average='weighted')\n",
        "\n",
        "# Add Metrics column\n",
        "df['Metrics'] = ''\n",
        "df.at[0, 'Metrics'] = f\"Overall Accuracy: {accuracy:.2%}\\nYes: {yes_percentage:.2%}\\nNo: {no_percentage:.2%}\\n\"\n",
        "df.at[1, 'Metrics'] = f\"Precision: {precision:.2%}\\nRecall: {recall:.2%}\\nF1 Score: {f1:.2%}\"\n",
        "\n",
        "# Reorder columns\n",
        "column_order = ['Input Text', 'Label', 'Predicted Label', 'Remarks', 'Metrics']\n",
        "df = df[column_order]\n",
        "\n",
        "# Save the updated DataFrame\n",
        "output_file = \"/content/drive/MyDrive/Thesis Personal/Data set/output_file_FT_K2.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Predictions completed and saved to '{output_file}'\")\n",
        "\n",
        "# Display the first few rows of the updated DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Display clustering results\n",
        "for sentence, label in zip(sentences, cluster_labels):\n",
        "    print(f'Sentence: {sentence} - Cluster: {label}')\n",
        "\n",
        "# Display a summary of the predicted labels and remarks\n",
        "print(\"\\nPredicted Label Distribution:\")\n",
        "print(df['Predicted Label'].value_counts())\n",
        "print(\"\\nRemarks Distribution:\")\n",
        "print(df['Remarks'].value_counts(normalize=True))\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
        "print(f\"Precision: {precision:.2%}\")\n",
        "print(f\"Recall: {recall:.2%}\")\n",
        "print(f\"F1 Score: {f1:.2%}\")\n",
        "\n",
        "# Print the output and size\n",
        "output_test2 = cluster_labels.tolist()\n",
        "print(output_test2)\n",
        "size = len(output_test2)\n",
        "print(size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VChCInRufZRo",
        "outputId": "20338d82-7b69-45de-ee90-9969d0db48a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.9440559440559441\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# True labels (ground truth)\n",
        "true_labels = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2]\n",
        "\n",
        "# Predicted labels (cluster assignments)\n",
        "predicted_labels = cluster_labels_km_ft\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm-pdD3AuLvI",
        "outputId": "da99ebc2-e7c9-48a0-e179-7bd741632ea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9444444444444444\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have the ground truth labels for the sentences\n",
        "true_labels = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2]  # Replace with your true labels\n",
        "\n",
        "# Assuming you have the cluster labels predicted by KMeans\n",
        "predicted_labels = output  # Replace with your predicted labels\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68wdnRqV-IRN"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "output_file_path = '/content/drive/MyDrive/Bangla dataset/Clustering/audio.csv'  # Path to the existing CSV file\n",
        "\n",
        "# Read existing data from the CSV file\n",
        "existing_data = []\n",
        "with open(output_file_path, mode='r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    existing_data = list(reader)\n",
        "\n",
        "# Update existing data with cluster labels\n",
        "updated_data = []\n",
        "for i, row in enumerate(existing_data):\n",
        "    if i == 0:\n",
        "        updated_data.append(row + ['Cluster Label'])  # Add the header for the new column\n",
        "    else:\n",
        "        updated_data.append\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UisH0FKjwr5d"
      },
      "source": [
        "# **CODE TEST 2 KMEANS++ -BERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OylMPVVDwucs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
        "model = AutoModel.from_pretrained(\"sagorsarker/bangla-bert-base\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfeV2Nq-12g8",
        "outputId": "2d0a2f2c-4d2a-4023-fbc1-eb593606756a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions completed and saved to '/content/drive/MyDrive/Thesis Personal/Data set/output_file_bangla_bert2.csv'\n",
            "                                          Input Text  Label  Predicted Label  \\\n",
            "0  সম্প্রতি বিশ্ববিদ্যালয় শাখা ছাত্রলীগের সাধারণ...      0                1   \n",
            "1  এসব অভিযোগের ব্যাপারে ছাত্রলীগের কেন্দ্রীয় সং...      0                1   \n",
            "2  বিভিন্ন সময়ে শাখা ছাত্রলীগের একাধিক সহসভাপতির...      0                1   \n",
            "3  রাজধানীর পলাশী এলাকায় ফাস্টফুডের দোকানের এক কর...      0                1   \n",
            "4  নূর উদ্দিন আহমেদ ঢাকা বিশ্ববিদ্যালয় শাখা ছাত্র...      0                1   \n",
            "\n",
            "  Remarks                                            Metrics  \n",
            "0      No  Overall Accuracy: 25.00%\\nYes: 25.00%\\nNo: 75....  \n",
            "1      No  Precision: 8.33%\\nRecall: 25.00%\\nF1 Score: 12...  \n",
            "2      No                                                     \n",
            "3      No                                                     \n",
            "4      No                                                     \n",
            "Sentence: সম্প্রতি বিশ্ববিদ্যালয় শাখা ছাত্রলীগের সাধারণ সম্পাদকের বিরুদ্ধে মেডিকেল প্রশ্নপত্র ফাঁসের অভিযোগ উঠেছে - Cluster: 1\n",
            "Sentence: এসব অভিযোগের ব্যাপারে ছাত্রলীগের কেন্দ্রীয় সংসদের যুগ্ম সাধারণ সম্পাদক ও তদন্ত কমিটির সদস্য আবদুল্লাহ হীল প্রথম আলোকে বলেন, তাঁরা সব বিষয়ে তদন্ত করবেন - Cluster: 1\n",
            "Sentence: বিভিন্ন সময়ে শাখা ছাত্রলীগের একাধিক সহসভাপতির বিরুদ্ধে চাঁদাবাজি, মারধর এবং ছাত্রদলের সঙ্গে সংশ্লিষ্ট থাকার অভিযোগ উঠেছে - Cluster: 1\n",
            "Sentence: রাজধানীর পলাশী এলাকায় ফাস্টফুডের দোকানের এক কর্মচারীকে মারধরের অভিযোগ উঠেছে ঢাকা বিশ্ববিদ্যালয় শাখা ছাত্রলীগের এক নেতার বিরুদ্ধে - Cluster: 1\n",
            "Sentence: নূর উদ্দিন আহমেদ ঢাকা বিশ্ববিদ্যালয় শাখা ছাত্রলীগের সাধারণ সম্পাদক তানভীর হাসান সৈকতের অনুসারী হিসেবে পরিচিত - Cluster: 1\n",
            "Sentence: রাজধানীর মিরপুরের বোটানিক্যাল গার্ডেন, পুরান ঢাকার বলধা গার্ডেনসহ দেশের ছয়টি উদ্যান ও ইকোপার্কে প্রবেশমূল্য বাড়ানোর সিদ্ধান্তকে অন্যায্য ও অবিবেচনাপ্রসূত আখ্যায়িত করে তা কমানোর দাবি জানিয়েছে ইনস্টিটিউট ফর প্ল্যানিং অ্যান্ড ডেভেলপমেন্ট - Cluster: 1\n",
            "Sentence: ১১৯ মিনিটে বদলি মেরিনোর গোল, জার্মানির হৃদয় ভেঙে সেমিফাইনালে স্পেন - Cluster: 0\n",
            "Sentence: কোয়ার্টার ফাইনাল থেকে বিদায়ের মধ্যে দিয়ে জার্মান তারকা টনি ক্রুসের বর্ণাঢ্য ফুটবল ক্যারিয়ারেরও হতাশজনক সমাপ্তি ঘটল - Cluster: 1\n",
            "Sentence: নয়তো স্লোভেনিয়ার বিপক্ষে ১০৫ মিনিটে পেনাল্টি মিস করে কি আর শিশুদের মতো কাঁদেন - Cluster: 0\n",
            "Sentence: এখনো গোল করার প্রতিটি সুযোগ লুফে নিতে চান রোনালদো - Cluster: 0\n",
            "Sentence: তবে ইউরোর শেষ ষোলোয় পেনাল্টি মিস ও ফ্রি–কিকে একের পর এক সুযোগ হাতছাড়া করার কারণে বেশ সমালোচনার মুখে পড়েছেন রোনালদো - Cluster: 0\n",
            "Sentence: যে কারণে আজ ফ্রান্সের বিপক্ষে ম্যাচের আগে কোচ রবার্তো মার্তিনেজকেও বিষয়টি নিয়ে কথা বলতে হয়েছে - Cluster: 0\n",
            "Sentence: ক্যারিয়ারে এখন পর্যন্ত ফ্রি–কিক থেকে ৬৩টি গোল করেছেন আল নাসর তারকা - Cluster: 0\n",
            "Sentence: বাংলাদেশ উদ্বেগজনক মাত্রার দূষণ এবং পরিবেশগত স্বাস্থ্য ঝুঁকিতে রয়েছে যা তুলনামূলক বেশি ক্ষতি করছে দরিদ্র, পাঁচ বছরের কম শিশু, বয়স্ক এবং নারীদের, যা বিশ্বব্যাংকের এক নতুন প্রতিবেদনে বলা হয়েছে - Cluster: 1\n",
            "Sentence: বাংলাদেশের জন্য পরিবেশের ঝুঁকি মোকাবেলা একই সঙ্গে উন্নয়ন ও অর্থনৈতিক অগ্রাধিকার - Cluster: 1\n",
            "Sentence: পরিবেশ দূষণ শিশুদের ওপর মারাত্বক প্রভাব ফেলছে - Cluster: 1\n",
            "Sentence: বায়ু দূষণ নিয়ন্ত্রণে সময়মতো এবং জরুরি হস্তক্ষেপ, উন্নত পানি, স্যানিটেশন ও হাইজিন (ওয়াশ) এবং সীসা দূষণ নিয়ন্ত্রণ প্রতি বছর ১ লাখ ৩৩ হাজারের বেশি অকালমৃত্যু ঠেকাতে পারে - Cluster: 1\n",
            "Sentence: সবুজ বিদ্যুৎ উৎপাদনে বিনিয়োগ,রান্নায় সবুজ জ্বালানি ব্যবহার এবং শিল্প-কারখানা থেকে দূষণ রোধে কঠোর নিয়ন্ত্রণ বায়ু দূষণ কমাতে পারে - Cluster: 1\n",
            "Sentence: সদ্য বিদায়ী ২০২৩-২৪ অর্থবছরের প্রথম ১০ মাস ও এর আগের ২০২২-২৩ অর্থবছরের প্রথম ১০ মাস মিলিয়ে মোট ২০ মাসে ৯ হাজার ৩১৪ কোটি ডলারের রপ্তানির তথ্য দিয়েছিল রপ্তানি উন্নয়ন ব্যুরো (ইপিবি) - Cluster: 1\n",
            "Sentence: তবে বাংলাদেশ ব্যাংক এখন বলছে, ওই সময় রপ্তানি হয়েছে ৬ হাজার ৯৮০ কোটি ডলার। তার মানে ২৫ শতাংশ রপ্তানির তথ্য উধাও হয়ে গেছে - Cluster: 1\n",
            "Sentence: প্তানির হিসাব দেশের লেনদেন ভারসাম্য ও বৈদেশিক মুদ্রার বিনিময় হারে প্রভাব ফেলে - Cluster: 1\n",
            "Sentence: এদিকে পণ্য রপ্তানির ২ হাজার ৩৩৪ কোটি ডলারের হিসাব কোথায় গেল, সে বিষয়ে নিশ্চুপ আছেন ইপিবির কর্মকর্তারা - Cluster: 1\n",
            "Sentence: রপ্তানির প্রকৃত তথ্যের ভিত্তিতে কেন্দ্রীয় ব্যাংক গত বুধবার লেনদেন ভারসাম্যের হিসাব করেছে - Cluster: 1\n",
            "Sentence: রপ্তানি তথ্যের হিসাবে ওলটপালট হওয়ায় গত বছরের জুলাই থেকে চলতি বছরের এপ্রিল পর্যন্ত লেনদেন ভারসাম্যে ঘাটতি হয়েছে ৫৫৬ কোটি ডলার - Cluster: 1\n",
            "\n",
            "Predicted Label Distribution:\n",
            "Predicted Label\n",
            "1    18\n",
            "0     6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Remarks Distribution:\n",
            "Remarks\n",
            "No     0.75\n",
            "Yes    0.25\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Accuracy: 25.00%\n",
            "Precision: 8.33%\n",
            "Recall: 25.00%\n",
            "F1 Score: 12.50%\n",
            "[1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the pre-trained tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
        "model = AutoModel.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
        "\n",
        "# Read the CSV file\n",
        "input_file = \"/content/drive/MyDrive/Thesis Personal/Data set/Bangla Input topics.csv\"\n",
        "\n",
        "# Check if the file exists\n",
        "if not os.path.exists(input_file):\n",
        "    print(f\"Error: The file {input_file} does not exist.\")\n",
        "    print(\"Please check the file path and try again.\")\n",
        "    exit()\n",
        "\n",
        "# If the file exists, read it\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Extract sentences from the 'Input Text' column\n",
        "sentences = df['Input Text'].tolist()\n",
        "\n",
        "# Generate sentence embeddings\n",
        "sentence_embeddings = []\n",
        "for sentence in sentences:\n",
        "    inputs = tokenizer.encode_plus(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        sentence_embedding = torch.mean(outputs.last_hidden_state, dim=1).squeeze()\n",
        "        sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "sentence_embeddings = torch.stack(sentence_embeddings).numpy()\n",
        "\n",
        "# Perform K-means clustering\n",
        "num_clusters = 2  # Number of clusters\n",
        "kmeans = KMeans(n_clusters=num_clusters, init='k-means++', random_state=42)\n",
        "kmeans.fit(sentence_embeddings)\n",
        "\n",
        "# Get cluster labels\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "# Add predicted labels to the DataFrame\n",
        "df['Predicted Label'] = cluster_labels\n",
        "\n",
        "# Add remarks column by comparing 'Label' and 'Predicted Label'\n",
        "df['Remarks'] = df.apply(lambda row: 'Yes' if row['Label'] == row['Predicted Label'] else 'No', axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (df['Remarks'] == 'Yes').mean()\n",
        "yes_percentage = (df['Remarks'] == 'Yes').mean()\n",
        "no_percentage = (df['Remarks'] == 'No').mean()\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(df['Label'], df['Predicted Label'], average='weighted')\n",
        "recall = recall_score(df['Label'], df['Predicted Label'], average='weighted')\n",
        "f1 = f1_score(df['Label'], df['Predicted Label'], average='weighted')\n",
        "\n",
        "# Add Metrics column\n",
        "df['Metrics'] = ''\n",
        "df.at[0, 'Metrics'] = f\"Overall Accuracy: {accuracy:.2%}\\nYes: {yes_percentage:.2%}\\nNo: {no_percentage:.2%}\\n\"\n",
        "df.at[1, 'Metrics'] = f\"Precision: {precision:.2%}\\nRecall: {recall:.2%}\\nF1 Score: {f1:.2%}\"\n",
        "\n",
        "# Reorder columns\n",
        "column_order = ['Input Text', 'Label', 'Predicted Label', 'Remarks', 'Metrics']\n",
        "df = df[column_order]\n",
        "\n",
        "# Save the updated DataFrame\n",
        "output_file = \"/content/drive/MyDrive/Thesis Personal/Data set/output_file_bangla_bert2.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Predictions completed and saved to '{output_file}'\")\n",
        "\n",
        "# Display the first few rows of the updated DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Display clustering results\n",
        "for sentence, label in zip(sentences, cluster_labels):\n",
        "    print(f'Sentence: {sentence} - Cluster: {label}')\n",
        "\n",
        "# Display a summary of the predicted labels and remarks\n",
        "print(\"\\nPredicted Label Distribution:\")\n",
        "print(df['Predicted Label'].value_counts())\n",
        "print(\"\\nRemarks Distribution:\")\n",
        "print(df['Remarks'].value_counts(normalize=True))\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
        "print(f\"Precision: {precision:.2%}\")\n",
        "print(f\"Recall: {recall:.2%}\")\n",
        "print(f\"F1 Score: {f1:.2%}\")\n",
        "\n",
        "# Print the output and size as in the original code\n",
        "output_test2 = cluster_labels.tolist()\n",
        "print(output_test2)\n",
        "size = len(output_test2)\n",
        "print(size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G98UTeqCSGSB"
      },
      "source": [
        "# **Code Test 3 KMeans++, Word2vec**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLW2Ve7g9RZP",
        "outputId": "628c8bab-6102-441c-8b7a-8f5c9bd89b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# True labels or ground truth cluster assignments\n",
        "true_labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "\n",
        "# Predicted labels from the clustering algorithm\n",
        "predicted_labels = cluster_labels_km_bt\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "print(\"F1 Score:\", f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is_hbfRzSE7f",
        "outputId": "272e0a5a-9960-4e29-cb22-9c3fbe6255ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions completed and saved to '/content/drive/MyDrive/Thesis Personal/Data set/output_file_Word2Vec_K2.csv'\n",
            "                                          Input Text  Label  Predicted Label  \\\n",
            "0  সম্প্রতি বিশ্ববিদ্যালয় শাখা ছাত্রলীগের সাধারণ...      0                0   \n",
            "1  এসব অভিযোগের ব্যাপারে ছাত্রলীগের কেন্দ্রীয় সং...      0                0   \n",
            "2  বিভিন্ন সময়ে শাখা ছাত্রলীগের একাধিক সহসভাপতির...      0                0   \n",
            "3  রাজধানীর পলাশী এলাকায় ফাস্টফুডের দোকানের এক কর...      0                0   \n",
            "4  নূর উদ্দিন আহমেদ ঢাকা বিশ্ববিদ্যালয় শাখা ছাত্র...      0                0   \n",
            "\n",
            "  Remarks                                            Metrics  \n",
            "0     Yes  Overall Accuracy: 25.00%\\nYes: 25.00%\\nNo: 75....  \n",
            "1     Yes  Precision: 29.53%\\nRecall: 25.00%\\nF1 Score: 1...  \n",
            "2     Yes                                                     \n",
            "3     Yes                                                     \n",
            "4     Yes                                                     \n",
            "Sentence: সম্প্রতি বিশ্ববিদ্যালয় শাখা ছাত্রলীগের সাধারণ সম্পাদকের বিরুদ্ধে মেডিকেল প্রশ্নপত্র ফাঁসের অভিযোগ উঠেছে - Cluster: 0\n",
            "Sentence: এসব অভিযোগের ব্যাপারে ছাত্রলীগের কেন্দ্রীয় সংসদের যুগ্ম সাধারণ সম্পাদক ও তদন্ত কমিটির সদস্য আবদুল্লাহ হীল প্রথম আলোকে বলেন, তাঁরা সব বিষয়ে তদন্ত করবেন - Cluster: 0\n",
            "Sentence: বিভিন্ন সময়ে শাখা ছাত্রলীগের একাধিক সহসভাপতির বিরুদ্ধে চাঁদাবাজি, মারধর এবং ছাত্রদলের সঙ্গে সংশ্লিষ্ট থাকার অভিযোগ উঠেছে - Cluster: 0\n",
            "Sentence: রাজধানীর পলাশী এলাকায় ফাস্টফুডের দোকানের এক কর্মচারীকে মারধরের অভিযোগ উঠেছে ঢাকা বিশ্ববিদ্যালয় শাখা ছাত্রলীগের এক নেতার বিরুদ্ধে - Cluster: 0\n",
            "Sentence: নূর উদ্দিন আহমেদ ঢাকা বিশ্ববিদ্যালয় শাখা ছাত্রলীগের সাধারণ সম্পাদক তানভীর হাসান সৈকতের অনুসারী হিসেবে পরিচিত - Cluster: 0\n",
            "Sentence: রাজধানীর মিরপুরের বোটানিক্যাল গার্ডেন, পুরান ঢাকার বলধা গার্ডেনসহ দেশের ছয়টি উদ্যান ও ইকোপার্কে প্রবেশমূল্য বাড়ানোর সিদ্ধান্তকে অন্যায্য ও অবিবেচনাপ্রসূত আখ্যায়িত করে তা কমানোর দাবি জানিয়েছে ইনস্টিটিউট ফর প্ল্যানিং অ্যান্ড ডেভেলপমেন্ট - Cluster: 0\n",
            "Sentence: ১১৯ মিনিটে বদলি মেরিনোর গোল, জার্মানির হৃদয় ভেঙে সেমিফাইনালে স্পেন - Cluster: 0\n",
            "Sentence: কোয়ার্টার ফাইনাল থেকে বিদায়ের মধ্যে দিয়ে জার্মান তারকা টনি ক্রুসের বর্ণাঢ্য ফুটবল ক্যারিয়ারেরও হতাশজনক সমাপ্তি ঘটল - Cluster: 0\n",
            "Sentence: নয়তো স্লোভেনিয়ার বিপক্ষে ১০৫ মিনিটে পেনাল্টি মিস করে কি আর শিশুদের মতো কাঁদেন - Cluster: 0\n",
            "Sentence: এখনো গোল করার প্রতিটি সুযোগ লুফে নিতে চান রোনালদো - Cluster: 0\n",
            "Sentence: তবে ইউরোর শেষ ষোলোয় পেনাল্টি মিস ও ফ্রি–কিকে একের পর এক সুযোগ হাতছাড়া করার কারণে বেশ সমালোচনার মুখে পড়েছেন রোনালদো - Cluster: 0\n",
            "Sentence: যে কারণে আজ ফ্রান্সের বিপক্ষে ম্যাচের আগে কোচ রবার্তো মার্তিনেজকেও বিষয়টি নিয়ে কথা বলতে হয়েছে - Cluster: 0\n",
            "Sentence: ক্যারিয়ারে এখন পর্যন্ত ফ্রি–কিক থেকে ৬৩টি গোল করেছেন আল নাসর তারকা - Cluster: 0\n",
            "Sentence: বাংলাদেশ উদ্বেগজনক মাত্রার দূষণ এবং পরিবেশগত স্বাস্থ্য ঝুঁকিতে রয়েছে যা তুলনামূলক বেশি ক্ষতি করছে দরিদ্র, পাঁচ বছরের কম শিশু, বয়স্ক এবং নারীদের, যা বিশ্বব্যাংকের এক নতুন প্রতিবেদনে বলা হয়েছে - Cluster: 0\n",
            "Sentence: বাংলাদেশের জন্য পরিবেশের ঝুঁকি মোকাবেলা একই সঙ্গে উন্নয়ন ও অর্থনৈতিক অগ্রাধিকার - Cluster: 0\n",
            "Sentence: পরিবেশ দূষণ শিশুদের ওপর মারাত্বক প্রভাব ফেলছে - Cluster: 1\n",
            "Sentence: বায়ু দূষণ নিয়ন্ত্রণে সময়মতো এবং জরুরি হস্তক্ষেপ, উন্নত পানি, স্যানিটেশন ও হাইজিন (ওয়াশ) এবং সীসা দূষণ নিয়ন্ত্রণ প্রতি বছর ১ লাখ ৩৩ হাজারের বেশি অকালমৃত্যু ঠেকাতে পারে - Cluster: 0\n",
            "Sentence: সবুজ বিদ্যুৎ উৎপাদনে বিনিয়োগ,রান্নায় সবুজ জ্বালানি ব্যবহার এবং শিল্প-কারখানা থেকে দূষণ রোধে কঠোর নিয়ন্ত্রণ বায়ু দূষণ কমাতে পারে - Cluster: 0\n",
            "Sentence: সদ্য বিদায়ী ২০২৩-২৪ অর্থবছরের প্রথম ১০ মাস ও এর আগের ২০২২-২৩ অর্থবছরের প্রথম ১০ মাস মিলিয়ে মোট ২০ মাসে ৯ হাজার ৩১৪ কোটি ডলারের রপ্তানির তথ্য দিয়েছিল রপ্তানি উন্নয়ন ব্যুরো (ইপিবি) - Cluster: 0\n",
            "Sentence: তবে বাংলাদেশ ব্যাংক এখন বলছে, ওই সময় রপ্তানি হয়েছে ৬ হাজার ৯৮০ কোটি ডলার। তার মানে ২৫ শতাংশ রপ্তানির তথ্য উধাও হয়ে গেছে - Cluster: 0\n",
            "Sentence: প্তানির হিসাব দেশের লেনদেন ভারসাম্য ও বৈদেশিক মুদ্রার বিনিময় হারে প্রভাব ফেলে - Cluster: 0\n",
            "Sentence: এদিকে পণ্য রপ্তানির ২ হাজার ৩৩৪ কোটি ডলারের হিসাব কোথায় গেল, সে বিষয়ে নিশ্চুপ আছেন ইপিবির কর্মকর্তারা - Cluster: 0\n",
            "Sentence: রপ্তানির প্রকৃত তথ্যের ভিত্তিতে কেন্দ্রীয় ব্যাংক গত বুধবার লেনদেন ভারসাম্যের হিসাব করেছে - Cluster: 0\n",
            "Sentence: রপ্তানি তথ্যের হিসাবে ওলটপালট হওয়ায় গত বছরের জুলাই থেকে চলতি বছরের এপ্রিল পর্যন্ত লেনদেন ভারসাম্যে ঘাটতি হয়েছে ৫৫৬ কোটি ডলার - Cluster: 0\n",
            "\n",
            "Predicted Label Distribution:\n",
            "Predicted Label\n",
            "0    23\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Remarks Distribution:\n",
            "Remarks\n",
            "No     0.75\n",
            "Yes    0.25\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Accuracy: 25.00%\n",
            "Precision: 29.53%\n",
            "Recall: 25.00%\n",
            "F1 Score: 14.58%\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "24\n",
            "Word2Vec model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK data for tokenization\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Read the CSV file\n",
        "input_file = \"/content/drive/MyDrive/Thesis Personal/Data set/Bangla Input topics.csv\"\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Extract sentences from the 'Input Text' column\n",
        "sentences = df['Input Text'].tolist()\n",
        "\n",
        "# Tokenize sentences\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "\n",
        "# Train Word2Vec model\n",
        "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Function to get sentence embedding\n",
        "def get_sentence_embedding(sentence):\n",
        "    words = word_tokenize(sentence.lower())\n",
        "    word_vectors = [model.wv[word] for word in words if word in model.wv]\n",
        "    if len(word_vectors) == 0:\n",
        "        return np.zeros(model.vector_size)\n",
        "    return np.mean(word_vectors, axis=0)\n",
        "\n",
        "# Generate sentence embeddings\n",
        "sentence_embeddings = np.array([get_sentence_embedding(sentence) for sentence in sentences])\n",
        "\n",
        "# Perform K-means clustering\n",
        "num_clusters = 2  # Number of clusters\n",
        "kmeans = KMeans(n_clusters=num_clusters, init='k-means++', random_state=42, n_init=10)\n",
        "cluster_labels = kmeans.fit_predict(sentence_embeddings)\n",
        "\n",
        "# Add predicted labels to the DataFrame\n",
        "df['Predicted Label'] = cluster_labels\n",
        "\n",
        "# Add remarks column by comparing 'Label' and 'Predicted Label'\n",
        "df['Remarks'] = df.apply(lambda row: 'Yes' if row['Label'] == row['Predicted Label'] else 'No', axis=1)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = (df['Remarks'] == 'Yes').mean()\n",
        "yes_percentage = (df['Remarks'] == 'Yes').mean()\n",
        "no_percentage = (df['Remarks'] == 'No').mean()\n",
        "precision = precision_score(df['Label'], df['Predicted Label'], average='weighted')\n",
        "recall = recall_score(df['Label'], df['Predicted Label'], average='weighted')\n",
        "f1 = f1_score(df['Label'], df['Predicted Label'], average='weighted')\n",
        "\n",
        "# Add Metrics column\n",
        "df['Metrics'] = ''\n",
        "df.at[0, 'Metrics'] = f\"Overall Accuracy: {accuracy:.2%}\\nYes: {yes_percentage:.2%}\\nNo: {no_percentage:.2%}\\n\"\n",
        "df.at[1, 'Metrics'] = f\"Precision: {precision:.2%}\\nRecall: {recall:.2%}\\nF1 Score: {f1:.2%}\"\n",
        "\n",
        "# Reorder columns\n",
        "column_order = ['Input Text', 'Label', 'Predicted Label', 'Remarks', 'Metrics']\n",
        "df = df[column_order]\n",
        "\n",
        "# Save the updated DataFrame\n",
        "output_file = \"/content/drive/MyDrive/Thesis Personal/Data set/output_file_Word2Vec_K2.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Predictions completed and saved to '{output_file}'\")\n",
        "\n",
        "# Display the first few rows of the updated DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Display clustering results\n",
        "for sentence, label in zip(sentences, cluster_labels):\n",
        "    print(f'Sentence: {sentence} - Cluster: {label}')\n",
        "\n",
        "# Display a summary of the predicted labels and remarks\n",
        "print(\"\\nPredicted Label Distribution:\")\n",
        "print(df['Predicted Label'].value_counts())\n",
        "print(\"\\nRemarks Distribution:\")\n",
        "print(df['Remarks'].value_counts(normalize=True))\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
        "print(f\"Precision: {precision:.2%}\")\n",
        "print(f\"Recall: {recall:.2%}\")\n",
        "print(f\"F1 Score: {f1:.2%}\")\n",
        "\n",
        "# Print the output and size\n",
        "output_test2 = cluster_labels.tolist()\n",
        "print(output_test2)\n",
        "size = len(output_test2)\n",
        "print(size)\n",
        "\n",
        "# Save the Word2Vec model\n",
        "model.save(\"/content/drive/MyDrive/Thesis Personal/word2vec_model.bin\")\n",
        "print(\"Word2Vec model saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24EQuiCVKt3Z",
        "outputId": "68f4402b-0dcd-4c8c-9f8b-1dfed69f110f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have the ground truth labels for the sentences\n",
        "true_labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1]  # Replace with your true labels\n",
        "\n",
        "# Assuming you have the cluster labels predicted by KMeans\n",
        "predicted_labels = output_test2  # Replace with your predicted labels\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH-fyA9VS_px",
        "outputId": "9b3434e4-16b6-439f-e08f-7160324b09a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have the ground truth labels for the sentences\n",
        "true_labels = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]  # Replace with your true labels\n",
        "\n",
        "# Assuming you have the cluster labels predicted by KMeans\n",
        "predicted_labels = output_test3  # Replace with your predicted labels\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9artzZ477mM",
        "outputId": "e7d63f02-f2cc-4bd7-f735-8c951a6a492f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.6703296703296704\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# True labels (ground truth)\n",
        "true_labels = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
        "\n",
        "# Predicted labels (cluster assignments)\n",
        "predicted_labels = cluster_labels\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"F1 Score: {f1}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AvlaMX1XlJW"
      },
      "source": [
        "# DBSCAN, FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGq_yBenXkNV",
        "outputId": "f4a3ec6c-3db2-4c7b-e152-6af63d4aed85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.bn.300.bin.gz\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: সম্প্রতি বিশ্ববিদ্যালয় শাখা ছাত্রলীগের সাধারণ সম্পাদকের বিরুদ্ধে মেডিকেল প্রশ্নপত্র ফাঁসের অভিযোগ উঠেছে\n",
            "Label: 0\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: এসব অভিযোগের ব্যাপারে ছাত্রলীগের কেন্দ্রীয় সংসদের যুগ্ম সাধারণ সম্পাদক ও তদন্ত কমিটির সদস্য আবদুল্লাহ হীল প্রথম আলোকে বলেন, তাঁরা সব বিষয়ে তদন্ত করবেন\n",
            "Label: 0\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: বিভিন্ন সময়ে শাখা ছাত্রলীগের একাধিক সহসভাপতির বিরুদ্ধে চাঁদাবাজি, মারধর এবং ছাত্রদলের সঙ্গে সংশ্লিষ্ট থাকার অভিযোগ উঠেছে\n",
            "Label: 0\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: রাজধানীর পলাশী এলাকায় ফাস্টফুডের দোকানের এক কর্মচারীকে মারধরের অভিযোগ উঠেছে ঢাকা বিশ্ববিদ্যালয় শাখা ছাত্রলীগের এক নেতার বিরুদ্ধে\n",
            "Label: 0\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: নূর উদ্দিন আহমেদ ঢাকা বিশ্ববিদ্যালয় শাখা ছাত্রলীগের সাধারণ সম্পাদক তানভীর হাসান সৈকতের অনুসারী হিসেবে পরিচিত\n",
            "Label: 0\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: রাজধানীর মিরপুরের বোটানিক্যাল গার্ডেন, পুরান ঢাকার বলধা গার্ডেনসহ দেশের ছয়টি উদ্যান ও ইকোপার্কে প্রবেশমূল্য বাড়ানোর সিদ্ধান্তকে অন্যায্য ও অবিবেচনাপ্রসূত আখ্যায়িত করে তা কমানোর দাবি জানিয়েছে ইনস্টিটিউট ফর প্ল্যানিং অ্যান্ড ডেভেলপমেন্ট\n",
            "Label: 1\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: ১১৯ মিনিটে বদলি মেরিনোর গোল, জার্মানির হৃদয় ভেঙে সেমিফাইনালে স্পেন\n",
            "Label: 2\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: কোয়ার্টার ফাইনাল থেকে বিদায়ের মধ্যে দিয়ে জার্মান তারকা টনি ক্রুসের বর্ণাঢ্য ফুটবল ক্যারিয়ারেরও হতাশজনক সমাপ্তি ঘটল\n",
            "Label: 2\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: নয়তো স্লোভেনিয়ার বিপক্ষে ১০৫ মিনিটে পেনাল্টি মিস করে কি আর শিশুদের মতো কাঁদেন\n",
            "Label: 2\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: এখনো গোল করার প্রতিটি সুযোগ লুফে নিতে চান রোনালদো\n",
            "Label: 2\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: তবে ইউরোর শেষ ষোলোয় পেনাল্টি মিস ও ফ্রি–কিকে একের পর এক সুযোগ হাতছাড়া করার কারণে বেশ সমালোচনার মুখে পড়েছেন রোনালদো\n",
            "Label: 2\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: যে কারণে আজ ফ্রান্সের বিপক্ষে ম্যাচের আগে কোচ রবার্তো মার্তিনেজকেও বিষয়টি নিয়ে কথা বলতে হয়েছে\n",
            "Label: 2\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: ক্যারিয়ারে এখন পর্যন্ত ফ্রি–কিক থেকে ৬৩টি গোল করেছেন আল নাসর তারকা\n",
            "Label: 2\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: বাংলাদেশ উদ্বেগজনক মাত্রার দূষণ এবং পরিবেশগত স্বাস্থ্য ঝুঁকিতে রয়েছে যা তুলনামূলক বেশি ক্ষতি করছে দরিদ্র, পাঁচ বছরের কম শিশু, বয়স্ক এবং নারীদের, যা বিশ্বব্যাংকের এক নতুন প্রতিবেদনে বলা হয়েছে\n",
            "Label: 1\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: বাংলাদেশের জন্য পরিবেশের ঝুঁকি মোকাবেলা একই সঙ্গে উন্নয়ন ও অর্থনৈতিক অগ্রাধিকার\n",
            "Label: 1\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: পরিবেশ দূষণ শিশুদের ওপর মারাত্বক প্রভাব ফেলছে\n",
            "Label: 1\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: বায়ু দূষণ নিয়ন্ত্রণে সময়মতো এবং জরুরি হস্তক্ষেপ, উন্নত পানি, স্যানিটেশন ও হাইজিন (ওয়াশ) এবং সীসা দূষণ নিয়ন্ত্রণ প্রতি বছর ১ লাখ ৩৩ হাজারের বেশি অকালমৃত্যু ঠেকাতে পারে\n",
            "Label: 1\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: সবুজ বিদ্যুৎ উৎপাদনে বিনিয়োগ,রান্নায় সবুজ জ্বালানি ব্যবহার এবং শিল্প-কারখানা থেকে দূষণ রোধে কঠোর নিয়ন্ত্রণ বায়ু দূষণ কমাতে পারে\n",
            "Label: 1\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: সদ্য বিদায়ী ২০২৩-২৪ অর্থবছরের প্রথম ১০ মাস ও এর আগের ২০২২-২৩ অর্থবছরের প্রথম ১০ মাস মিলিয়ে মোট ২০ মাসে ৯ হাজার ৩১৪ কোটি ডলারের রপ্তানির তথ্য দিয়েছিল রপ্তানি উন্নয়ন ব্যুরো (ইপিবি)\n",
            "Label: 3\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: তবে বাংলাদেশ ব্যাংক এখন বলছে, ওই সময় রপ্তানি হয়েছে ৬ হাজার ৯৮০ কোটি ডলার। তার মানে ২৫ শতাংশ রপ্তানির তথ্য উধাও হয়ে গেছে\n",
            "Label: 3\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: প্তানির হিসাব দেশের লেনদেন ভারসাম্য ও বৈদেশিক মুদ্রার বিনিময় হারে প্রভাব ফেলে\n",
            "Label: 3\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: এদিকে পণ্য রপ্তানির ২ হাজার ৩৩৪ কোটি ডলারের হিসাব কোথায় গেল, সে বিষয়ে নিশ্চুপ আছেন ইপিবির কর্মকর্তারা\n",
            "Label: 3\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: রপ্তানির প্রকৃত তথ্যের ভিত্তিতে কেন্দ্রীয় ব্যাংক গত বুধবার লেনদেন ভারসাম্যের হিসাব করেছে\n",
            "Label: 3\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Sentence: রপ্তানি তথ্যের হিসাবে ওলটপালট হওয়ায় গত বছরের জুলাই থেকে চলতি বছরের এপ্রিল পর্যন্ত লেনদেন ভারসাম্যে ঘাটতি হয়েছে ৫৫৬ কোটি ডলার\n",
            "Label: 3\n",
            "Predicted Label: -1\n",
            "Remarks: Incorrect\n",
            "Accuracy: 0\n",
            "\n",
            "Overall Accuracy: 0.00\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import fasttext.util\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "# Download and load the FastText model\n",
        "fasttext.util.download_model('bn', if_exists='ignore')\n",
        "model_path = 'cc.bn.300.bin'\n",
        "model = fasttext.load_model(model_path)\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/Thesis Personal/Data set/Bangla Input topics.csv')\n",
        "sentences = df['Input Text'].tolist()\n",
        "\n",
        "# Generate sentence embeddings\n",
        "sentence_embeddings = []\n",
        "for sentence in sentences:\n",
        "    words = sentence.split()\n",
        "    word_embeddings = [model.get_word_vector(word) for word in words]\n",
        "    sentence_embedding = np.mean(word_embeddings, axis=0)\n",
        "    sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "sentence_embeddings = np.array(sentence_embeddings)\n",
        "\n",
        "# Scale the sentence embeddings\n",
        "scaler = StandardScaler()\n",
        "sentence_embeddings = scaler.fit_transform(sentence_embeddings)\n",
        "\n",
        "# Apply DBSCAN clustering\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=2)\n",
        "dbscan.fit(sentence_embeddings)\n",
        "\n",
        "# Get cluster labels\n",
        "cluster_labels = dbscan.labels_\n",
        "\n",
        "# Add predictions to the DataFrame\n",
        "df['Predicted Label'] = cluster_labels\n",
        "\n",
        "# Compare Label and Predicted Label\n",
        "df['Remarks'] = df.apply(lambda row: 'Correct' if row['Label'] == row['Predicted Label'] else 'Incorrect', axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "df['Accuracy'] = df.apply(lambda row: 1 if row['Label'] == row['Predicted Label'] else 0, axis=1)\n",
        "accuracy = df['Accuracy'].mean()\n",
        "\n",
        "# Print results\n",
        "for _, row in df.iterrows():\n",
        "    print(f\"Sentence: {row['Input Text']}\")\n",
        "    print(f\"Label: {row['Label']}\")\n",
        "    print(f\"Predicted Label: {row['Predicted Label']}\")\n",
        "    print(f\"Remarks: {row['Remarks']}\")\n",
        "    print(f\"Accuracy: {row['Accuracy']}\")\n",
        "    print()\n",
        "\n",
        "print(f\"Overall Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Save results to CSV\n",
        "df.to_csv('output_file.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m2QjCLnpIgq"
      },
      "source": [
        "# DBSCAN+BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhdSRvZMpIGW",
        "outputId": "4d2014eb-b68c-44ec-aa0b-09d6dad5acf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF_n3H7PqJSJ",
        "outputId": "3efa73ce-33c1-4fa3-8332-23c4036b34f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at sagorsarker/bangla-bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: ফ্রান্সকে হারিয়ে ২০২২ ফিফা বিশ্বকাপ জিতে নিল আর্জেন্টিনা - Cluster: -1\n",
            "Sentence: বিশ্ব ক্রিকেট চ্যাম্পিয়ন ইংল্যান্ডকে ১৬ রানে হারালো বাংলাদেশ ক্রিকেট দল - Cluster: -1\n",
            "Sentence: রাজধানীতে আজ সারা দিন থেমে থেমে বৃষ্টি চলতে পারে বলে আবহাওয়া অধিদপ্তর পূর্বাভাস দিয়েছে - Cluster: -1\n",
            "Sentence: আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ঢাকাতে ৭ মিলিমিটার বৃষ্টি হয়। - Cluster: -1\n",
            "Sentence: আগামী ১৮ মার্চ আয়ারল্যান্ডের বিপক্ষে সিরিজ খেলবে বাংলাদেশ - Cluster: -1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sentences = [\n",
        "    'ফ্রান্সকে হারিয়ে ২০২২ ফিফা বিশ্বকাপ জিতে নিল আর্জেন্টিনা',\n",
        "    'বিশ্ব ক্রিকেট চ্যাম্পিয়ন ইংল্যান্ডকে ১৬ রানে হারালো বাংলাদেশ ক্রিকেট দল',\n",
        "    'রাজধানীতে আজ সারা দিন থেমে থেমে বৃষ্টি চলতে পারে বলে আবহাওয়া অধিদপ্তর পূর্বাভাস দিয়েছে',\n",
        "    'আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ঢাকাতে ৭ মিলিমিটার বৃষ্টি হয়।',\n",
        "    'আগামী ১৮ মার্চ আয়ারল্যান্ডের বিপক্ষে সিরিজ খেলবে বাংলাদেশ'\n",
        "]\n",
        "\n",
        "model_name = 'sagorsarker/bangla-bert-base'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "\n",
        "sentence_embeddings = []\n",
        "for sentence in sentences:\n",
        "    inputs = tokenizer.encode_plus(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        sentence_embedding = torch.mean(outputs.last_hidden_state, dim=1).squeeze()\n",
        "        sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "sentence_embeddings = torch.stack(sentence_embeddings).numpy()\n",
        "\n",
        "# Scale the embeddings\n",
        "scaler = StandardScaler()\n",
        "sentence_embeddings = scaler.fit_transform(sentence_embeddings)\n",
        "\n",
        "# Apply DBSCAN clustering\n",
        "eps = 0.5  # DBSCAN epsilon\n",
        "min_samples = 2  # Minimum number of samples in a cluster\n",
        "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "cluster_labels = dbscan.fit_predict(sentence_embeddings)\n",
        "\n",
        "output = []\n",
        "for sentence, label in zip(sentences, cluster_labels):\n",
        "    print(f'Sentence: {sentence} - Cluster: {label}')\n",
        "    output.append(label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhaGKvup5uNT"
      },
      "source": [
        "# hierarchical clustering algorithm with bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBp_1Wp8-P7D",
        "outputId": "b6eb8e99-a5da-4e47-ed5c-367b8b0a8e73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnqB5vOh507o",
        "outputId": "b9259a85-0d02-42b3-b9d6-a9425dd7cfc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at sagorsarker/bangla-bert-base were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: ফ্রান্সকে হারিয়ে ২০২২ ফিফা বিশ্বকাপ জিতে নিল আর্জেন্টিনা - Cluster: 1\n",
            "Sentence: রাজশাহীর বাঘায় তিন দিনব্যাপী কৃষিপ্রযুক্তি মেলা শুরু হয়েছে - Cluster: 8\n",
            "Sentence: বিশ্ব ক্রিকেট চ্যাম্পিয়ন ইংল্যান্ডকে ১৬ রানে হারালো বাংলাদেশ ক্রিকেট দল - Cluster: 2\n",
            "Sentence: আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ৭ মিলিমিটার বৃষ্টি হয় - Cluster: 6\n",
            "Sentence: রাজধানীতে আজ সারা দিন থেমে থেমে বৃষ্টি চলতে পারে বলে আবহাওয়া অধিদপ্তর পূর্বাভাস দিয়েছে - Cluster: 4\n",
            "Sentence: এবারের ঘূর্ণিঝড়ে আট বর্গকিলোমিটার আয়তনের এই দ্বীপে দুই হাজারের বেশি ঘরবাড়ি ও দোকানপাট ক্ষতিগ্রস্ত হয়েছে - Cluster: 5\n",
            "Sentence: আগামী ১৮ মার্চ আয়ারল্যান্ডের বিপক্ষে সিরিজ খেলবে বাংলাদেশ - Cluster: 3\n",
            "Sentence: অন্যান্য বছরের চেয়ে এ মৌসুমে আরও বেশি আম রপ্তানি করা হবে - Cluster: 7\n",
            "Sentence: পৃথিবীতে গত তিন বছরে কৃষি খাতে যারা ভালো করেছে, তাদের মধ্যে রয়েছে বাংলাদেশ - Cluster: 9\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Load the pre-trained Bangla BERT model and tokenizer\n",
        "model_name = \"sagorsarker/bangla-bert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Define the sentences to be clustered\n",
        "sentences = [\n",
        "    \"ফ্রান্সকে হারিয়ে ২০২২ ফিফা বিশ্বকাপ জিতে নিল আর্জেন্টিনা\",\n",
        "    \"রাজশাহীর বাঘায় তিন দিনব্যাপী কৃষিপ্রযুক্তি মেলা শুরু হয়েছে\",\n",
        "    \"বিশ্ব ক্রিকেট চ্যাম্পিয়ন ইংল্যান্ডকে ১৬ রানে হারালো বাংলাদেশ ক্রিকেট দল\",\n",
        "    \"আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ৭ মিলিমিটার বৃষ্টি হয়\",\n",
        "    \"রাজধানীতে আজ সারা দিন থেমে থেমে বৃষ্টি চলতে পারে বলে আবহাওয়া অধিদপ্তর পূর্বাভাস দিয়েছে\",\n",
        "    \"এবারের ঘূর্ণিঝড়ে আট বর্গকিলোমিটার আয়তনের এই দ্বীপে দুই হাজারের বেশি ঘরবাড়ি ও দোকানপাট ক্ষতিগ্রস্ত হয়েছে\",\n",
        "    \"আগামী ১৮ মার্চ আয়ারল্যান্ডের বিপক্ষে সিরিজ খেলবে বাংলাদেশ\",\n",
        "    \"অন্যান্য বছরের চেয়ে এ মৌসুমে আরও বেশি আম রপ্তানি করা হবে\",\n",
        "    \"পৃথিবীতে গত তিন বছরে কৃষি খাতে যারা ভালো করেছে, তাদের মধ্যে রয়েছে বাংলাদেশ\"\n",
        "]\n",
        "\n",
        "# Tokenize and encode the sentences using the Bangla BERT tokenizer\n",
        "encoded_inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Pass the encoded inputs through the Bangla BERT model to obtain sentence embeddings\n",
        "with torch.no_grad():\n",
        "    outputs = model(**encoded_inputs)\n",
        "    sentence_embeddings = torch.mean(outputs.last_hidden_state, dim=1)\n",
        "\n",
        "# Convert the sentence embeddings to a NumPy array\n",
        "sentence_embeddings = sentence_embeddings.numpy()\n",
        "\n",
        "# Perform hierarchical clustering using the linkage method\n",
        "linkage_matrix = linkage(sentence_embeddings, method='ward', metric='euclidean')\n",
        "\n",
        "# Set the threshold value for clustering\n",
        "threshold = 0.1  # Adjust this value based on your data and desired number of clusters\n",
        "\n",
        "# Apply clustering by assigning cluster labels using the fcluster function\n",
        "cluster_labels_hcb = fcluster(linkage_matrix, threshold, criterion='distance')\n",
        "\n",
        "# Print the sentences with their corresponding cluster labels\n",
        "for sentence, label in zip(sentences, cluster_labels_hcb):\n",
        "    print(f\"Sentence: {sentence} - Cluster: {label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46rAF2eMDdPW",
        "outputId": "04369c2e-6ba0-4986-c479-6a7dbc4cae40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.3333333333333333\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have the ground truth labels for the sentences\n",
        "true_labels = [1, 8, 1, 6, 6, 6, 1, 8, 8]  # Replace with your true labels\n",
        "\n",
        "# Assuming you have the cluster labels predicted by KMeans\n",
        "predicted_labels = cluster_labels_hcb  # Replace with your predicted labels\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUS8NfqsVGAt",
        "outputId": "e0c7605d-4057-42c1-c61c-60521ba2ef4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.5\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# True labels (ground truth)\n",
        "true_labels = [1, 8, 1, 6, 6, 6, 1, 8, 8]\n",
        "\n",
        "# Predicted labels (cluster assignments)\n",
        "predicted_labels = cluster_labels\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PMAdzK59rzv"
      },
      "source": [
        "# hierarchical clustering+FT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNGOhq809uNw",
        "outputId": "9838a63d-5b3b-4299-8d18-e87f8b1df072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: ফ্রান্সকে হারিয়ে ২০২২ ফিফা বিশ্বকাপ জিতে নিল আর্জেন্টিনা - Cluster: 4\n",
            "Sentence: রাজশাহীর বাঘায় তিন দিনব্যাপী কৃষিপ্রযুক্তি মেলা শুরু হয়েছে - Cluster: 2\n",
            "Sentence: বিশ্ব ক্রিকেট চ্যাম্পিয়ন ইংল্যান্ডকে ১৬ রানে হারালো বাংলাদেশ ক্রিকেট দল - Cluster: 3\n",
            "Sentence: আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ৭ মিলিমিটার বৃষ্টি হয় - Cluster: 1\n",
            "Sentence: রাজধানীতে আজ সারা দিন থেমে থেমে বৃষ্টি চলতে পারে বলে আবহাওয়া অধিদপ্তর পূর্বাভাস দিয়েছে - Cluster: 1\n",
            "Sentence: এবারের ঘূর্ণিঝড়ে আট বর্গকিলোমিটার আয়তনের এই দ্বীপে দুই হাজারের বেশি ঘরবাড়ি ও দোকানপাট ক্ষতিগ্রস্ত হয়েছে - Cluster: 2\n",
            "Sentence: আগামী ১৮ মার্চ আয়ারল্যান্ডের বিপক্ষে সিরিজ খেলবে বাংলাদেশ - Cluster: 3\n",
            "Sentence: অন্যান্য বছরের চেয়ে এ মৌসুমে আরও বেশি আম রপ্তানি করা হবে - Cluster: 2\n",
            "Sentence: পৃথিবীতে গত তিন বছরে কৃষি খাতে যারা ভালো করেছে, তাদের মধ্যে রয়েছে বাংলাদেশ - Cluster: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "<ipython-input-1-5a698d683a5d>:39: ClusterWarning: scipy.cluster: The symmetric non-negative hollow observation matrix looks suspiciously like an uncondensed distance matrix\n",
            "  Z = linkage(distances, method='ward')\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import fasttext.util\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "fasttext.util.download_model('bn', if_exists='ignore')\n",
        "\n",
        "model_path = 'cc.bn.300.bin'\n",
        "model = fasttext.load_model(model_path)\n",
        "\n",
        "sentences = [\n",
        "    'ফ্রান্সকে হারিয়ে ২০২২ ফিফা বিশ্বকাপ জিতে নিল আর্জেন্টিনা',\n",
        "    'রাজশাহীর বাঘায় তিন দিনব্যাপী কৃষিপ্রযুক্তি মেলা শুরু হয়েছে',\n",
        "    'বিশ্ব ক্রিকেট চ্যাম্পিয়ন ইংল্যান্ডকে ১৬ রানে হারালো বাংলাদেশ ক্রিকেট দল',\n",
        "    'আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ৭ মিলিমিটার বৃষ্টি হয়',\n",
        "    'রাজধানীতে আজ সারা দিন থেমে থেমে বৃষ্টি চলতে পারে বলে আবহাওয়া অধিদপ্তর পূর্বাভাস দিয়েছে',\n",
        "    'এবারের ঘূর্ণিঝড়ে আট বর্গকিলোমিটার আয়তনের এই দ্বীপে দুই হাজারের বেশি ঘরবাড়ি ও দোকানপাট ক্ষতিগ্রস্ত হয়েছে',\n",
        "    'আগামী ১৮ মার্চ আয়ারল্যান্ডের বিপক্ষে সিরিজ খেলবে বাংলাদেশ',\n",
        "    'অন্যান্য বছরের চেয়ে এ মৌসুমে আরও বেশি আম রপ্তানি করা হবে',\n",
        "    'পৃথিবীতে গত তিন বছরে কৃষি খাতে যারা ভালো করেছে, তাদের মধ্যে রয়েছে বাংলাদেশ'\n",
        "]\n",
        "\n",
        "# Calculate sentence embeddings\n",
        "sentence_embeddings = []\n",
        "for sentence in sentences:\n",
        "    words = sentence.split()\n",
        "    word_embeddings = [model.get_word_vector(word) for word in words]\n",
        "    sentence_embedding = np.mean(word_embeddings, axis=0)\n",
        "    sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "sentence_embeddings = np.array(sentence_embeddings)\n",
        "\n",
        "# Calculate cosine distance matrix\n",
        "distances = cosine_distances(sentence_embeddings)\n",
        "\n",
        "# Perform hierarchical clustering\n",
        "Z = linkage(distances, method='ward')\n",
        "\n",
        "# Plot dendrogram\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# dendrogram(Z, labels=sentences, orientation='top')\n",
        "# plt.xlabel('Sentences')\n",
        "# plt.ylabel('Distance')\n",
        "# # plt.title('Hierarchical Clustering Dendrogram')\n",
        "# plt.show()\n",
        "\n",
        "# Set the threshold for clustering\n",
        "threshold = 0.7\n",
        "\n",
        "# Perform clustering based on the threshold\n",
        "clusters_hc_ft = fcluster(Z, threshold, criterion='distance')\n",
        "\n",
        "# Print the sentence-cluster mapping\n",
        "output = []\n",
        "for sentence, cluster in zip(sentences, clusters_hc_ft):\n",
        "    print(f'Sentence: {sentence} - Cluster: {cluster}')\n",
        "    output.append(cluster)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdAOOjAnM6Jz",
        "outputId": "04fc13dc-069b-47ae-ab43-c1c42c8b20e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clustering Accuracy: 66.66666666666666%\n"
          ]
        }
      ],
      "source": [
        "ground_truth_labels = [4, 2, 4, 1, 1, 1, 4, 2, 2]  # Ground truth labels for each sentence\n",
        "\n",
        "# Calculate accuracy\n",
        "correct = 0\n",
        "for true_label, cluster_label in zip(ground_truth_labels, clusters_hc_ft):\n",
        "    if true_label == cluster_label:\n",
        "        correct += 1\n",
        "\n",
        "accuracy = correct / len(ground_truth_labels) * 100\n",
        "print(f\"Clustering Accuracy: {accuracy}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yu9r_KQWr98",
        "outputId": "7288b7b3-d0fd-42a6-83c5-25db728b403d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.719047619047619\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# True labels (ground truth)\n",
        "true_labels = [4, 2, 4, 1, 1, 1, 4, 2, 2]\n",
        "\n",
        "# Predicted labels (cluster assignments)\n",
        "predicted_labels = clusters_hc_ft\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzCbZlosYQgk"
      },
      "source": [
        "# hierarchical clustering+Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC0Fo4_3YVgR",
        "outputId": "0387010d-81d5-48fd-82af-c964e308552f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: ফ্রান্সকে হারিয়ে ২০২২ ফিফা বিশ্বকাপ জিতে নিল আর্জেন্টিনা - Cluster: 1\n",
            "Sentence: মাছ প্রক্রিয়াজাতকরণ বর্তমান বিশ্বে বিভিন্ন দেশে বেশ জনপ্রিয় - Cluster: 1\n",
            "Sentence: বিশ্ব ক্রিকেট চ্যাম্পিয়ন ইংল্যান্ডকে ১৬ রানে হারালো বাংলাদেশ ক্রিকেট দল - Cluster: 1\n",
            "Sentence: আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ৭ মিলিমিটার বৃষ্টি হয় - Cluster: 1\n",
            "Sentence: রাজধানীতে আজ সারা দিন থেমে থেমে বৃষ্টি চলতে পারে বলে আবহাওয়া অধিদপ্তর পূর্বাভাস দিয়েছে - Cluster: 1\n",
            "Sentence: এবারের ঘূর্ণিঝড়ে আট বর্গকিলোমিটার আয়তনের এই দ্বীপে দুই হাজারের বেশি ঘরবাড়ি ও দোকানপাট ক্ষতিগ্রস্ত হয়েছে - Cluster: 1\n",
            "Sentence: দেশের অন্যতম পর্যটনকেন্দ্র হিসেবে বিবেচিত এই দ্বীপের জনসংখ্যা প্রায় ১১ হাজার - Cluster: 1\n",
            "Sentence: আগামী ১৮ মার্চ আয়ারল্যান্ডের বিপক্ষে সিরিজ খেলবে বাংলাদেশ - Cluster: 1\n",
            "Sentence: পৃথিবীতে গত তিন বছরে কৃষি খাতে যারা ভালো করেছে, তাদের মধ্যে রয়েছে বাংলাদেশ - Cluster: 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "\n",
        "\n",
        "sentences = [\n",
        "    'ফ্রান্সকে হারিয়ে ২০২২ ফিফা বিশ্বকাপ জিতে নিল আর্জেন্টিনা',\n",
        "    'মাছ প্রক্রিয়াজাতকরণ বর্তমান বিশ্বে বিভিন্ন দেশে বেশ জনপ্রিয়',\n",
        "    'বিশ্ব ক্রিকেট চ্যাম্পিয়ন ইংল্যান্ডকে ১৬ রানে হারালো বাংলাদেশ ক্রিকেট দল',\n",
        "    'আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ৭ মিলিমিটার বৃষ্টি হয়',\n",
        "    'রাজধানীতে আজ সারা দিন থেমে থেমে বৃষ্টি চলতে পারে বলে আবহাওয়া অধিদপ্তর পূর্বাভাস দিয়েছে',\n",
        "    'এবারের ঘূর্ণিঝড়ে আট বর্গকিলোমিটার আয়তনের এই দ্বীপে দুই হাজারের বেশি ঘরবাড়ি ও দোকানপাট ক্ষতিগ্রস্ত হয়েছে',\n",
        "    'দেশের অন্যতম পর্যটনকেন্দ্র হিসেবে বিবেচিত এই দ্বীপের জনসংখ্যা প্রায় ১১ হাজার',\n",
        "    'আগামী ১৮ মার্চ আয়ারল্যান্ডের বিপক্ষে সিরিজ খেলবে বাংলাদেশ',\n",
        "    'পৃথিবীতে গত তিন বছরে কৃষি খাতে যারা ভালো করেছে, তাদের মধ্যে রয়েছে বাংলাদেশ'\n",
        "]\n",
        "\n",
        "# Preprocess the sentences (tokenization, lowercasing, etc.)\n",
        "preprocessed_sentences = [sentence.lower().split() for sentence in sentences]\n",
        "\n",
        "# Train a Word2Vec model on the preprocessed sentences\n",
        "model = Word2Vec(preprocessed_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Create a dictionary mapping words to their corresponding vectors\n",
        "word_vectors = model.wv\n",
        "\n",
        "# Function to obtain the sentence embedding by averaging word vectors\n",
        "def get_sentence_embedding(sentence):\n",
        "    embeddings = [word_vectors[word] for word in sentence if word in word_vectors]\n",
        "    if embeddings:\n",
        "        return np.mean(embeddings, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "# Obtain sentence embeddings for each sentence\n",
        "sentence_embeddings = [get_sentence_embedding(sentence) for sentence in preprocessed_sentences]\n",
        "\n",
        "# Perform hierarchical clustering using the linkage method\n",
        "linkage_matrix = linkage(sentence_embeddings, method='ward', metric='euclidean')\n",
        "\n",
        "# Set the threshold value for clustering\n",
        "threshold = 1.0  # Adjust this value based on your data and desired number of clusters\n",
        "\n",
        "# Apply clustering by assigning cluster labels using the fcluster function\n",
        "cluster_labels = fcluster(linkage_matrix, threshold, criterion='distance')\n",
        "\n",
        "# Print the sentences with their corresponding cluster labels\n",
        "for sentence, label in zip(sentences, cluster_labels):\n",
        "    print(f\"Sentence: {sentence} - Cluster: {label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXZSfVil6lO4"
      },
      "source": [
        "# Kmeans+BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24yDUjhkM3mQ",
        "outputId": "1b933564-af00-465f-ea39-295ff1acfa95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install torch\n",
        "!pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXNL6q6m6rZq",
        "outputId": "07b7b412-857f-4145-d32a-b2e334cd1d6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at sagorsarker/bangla-bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: ফ্রান্সকে হারিয়ে ২০২২ ফিফা বিশ্বকাপ জিতে নিল আর্জেন্টিনা - Cluster: 1\n",
            "Sentence: রাজশাহীর বাঘায় তিন দিনব্যাপী কৃষিপ্রযুক্তি মেলা শুরু হয়েছে - Cluster: 0\n",
            "Sentence: বিশ্ব ক্রিকেট চ্যাম্পিয়ন ইংল্যান্ডকে ১৬ রানে হারালো বাংলাদেশ ক্রিকেট দল - Cluster: 1\n",
            "Sentence: আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ৭ মিলিমিটার বৃষ্টি হয় - Cluster: 2\n",
            "Sentence: রাজধানীতে আজ সারা দিন থেমে থেমে বৃষ্টি চলতে পারে বলে আবহাওয়া অধিদপ্তর পূর্বাভাস দিয়েছে - Cluster: 2\n",
            "Sentence: এবারের ঘূর্ণিঝড়ে আট বর্গকিলোমিটার আয়তনের এই দ্বীপে দুই হাজারের বেশি ঘরবাড়ি ও দোকানপাট ক্ষতিগ্রস্ত হয়েছে - Cluster: 2\n",
            "Sentence: আগামী ১৮ মার্চ আয়ারল্যান্ডের বিপক্ষে সিরিজ খেলবে বাংলাদেশ - Cluster: 1\n",
            "Sentence: অন্যান্য বছরের চেয়ে এ মৌসুমে আরও বেশি আম রপ্তানি করা হবে - Cluster: 2\n",
            "Sentence: পৃথিবীতে গত তিন বছরে কৃষি খাতে যারা ভালো করেছে, তাদের মধ্যে রয়েছে বাংলাদেশ - Cluster: 2\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "sentences = [\n",
        "    'ফ্রান্সকে হারিয়ে ২০২২ ফিফা বিশ্বকাপ জিতে নিল আর্জেন্টিনা',\n",
        "    'রাজশাহীর বাঘায় তিন দিনব্যাপী কৃষিপ্রযুক্তি মেলা শুরু হয়েছে',\n",
        "    'বিশ্ব ক্রিকেট চ্যাম্পিয়ন ইংল্যান্ডকে ১৬ রানে হারালো বাংলাদেশ ক্রিকেট দল',\n",
        "    'আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ৭ মিলিমিটার বৃষ্টি হয়',\n",
        "    'রাজধানীতে আজ সারা দিন থেমে থেমে বৃষ্টি চলতে পারে বলে আবহাওয়া অধিদপ্তর পূর্বাভাস দিয়েছে',\n",
        "    'এবারের ঘূর্ণিঝড়ে আট বর্গকিলোমিটার আয়তনের এই দ্বীপে দুই হাজারের বেশি ঘরবাড়ি ও দোকানপাট ক্ষতিগ্রস্ত হয়েছে',\n",
        "    'আগামী ১৮ মার্চ আয়ারল্যান্ডের বিপক্ষে সিরিজ খেলবে বাংলাদেশ',\n",
        "    'অন্যান্য বছরের চেয়ে এ মৌসুমে আরও বেশি আম রপ্তানি করা হবে',\n",
        "    'পৃথিবীতে গত তিন বছরে কৃষি খাতে যারা ভালো করেছে, তাদের মধ্যে রয়েছে বাংলাদেশ'\n",
        "]\n",
        "\n",
        "# Load pre-trained Bangla BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
        "model = BertModel.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
        "\n",
        "# Set the device to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Encode sentences and get sentence embeddings\n",
        "sentence_embeddings = []\n",
        "with torch.no_grad():\n",
        "    for sentence in sentences:\n",
        "        inputs = tokenizer.encode_plus(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(**inputs)\n",
        "        sentence_embedding = torch.mean(outputs.last_hidden_state, dim=1).squeeze().cpu().numpy()\n",
        "        sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "# Perform K-means clustering\n",
        "sentence_embeddings = np.array(sentence_embeddings)\n",
        "num_clusters = 3  # Number of clusters\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(sentence_embeddings)\n",
        "cluster_labels_kb = kmeans.labels_\n",
        "\n",
        "# Print the clustering results\n",
        "output_kmeans = []\n",
        "for sentence, label in zip(sentences, cluster_labels_kb):\n",
        "    print(f'Sentence: {sentence} - Cluster: {label}')\n",
        "    output_kmeans.append(label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ej3wWfq1Nqjy",
        "outputId": "2bd63a49-eba4-4a6d-8a9b-be991f329c94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7777777777777778\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have the ground truth labels for the sentences\n",
        "true_labels = [1, 0, 1, 2, 2, 2, 1, 0, 0]  # Replace with your true labels\n",
        "\n",
        "# Assuming you have the cluster labels predicted by KMeans\n",
        "predicted_labels = output_kmeans  # Replace with your predicted labels\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4_KHRSPaB9i",
        "outputId": "f0fa8947-576f-476f-eb89-59ccb94007d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.75\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# True labels (ground truth)\n",
        "true_labels = [1, 0, 1, 2, 2, 2, 1, 0, 0]\n",
        "\n",
        "# Predicted labels (cluster assignments)\n",
        "predicted_labels = cluster_labels_kb\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXsQRsG9P8Nx"
      },
      "source": [
        "# kmeans+fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4q0EWd3xQS5H",
        "outputId": "1ea2ee87-74c8-4f04-c1d6-090ec5c191ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-23 21:02:57--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.bn.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 52.84.162.51, 52.84.162.20, 52.84.162.103, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|52.84.162.51|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3934298272 (3.7G) [application/octet-stream]\n",
            "Saving to: ‘cc.bn.300.bin.gz.1’\n",
            "\n",
            "cc.bn.300.bin.gz.1  100%[===================>]   3.66G   169MB/s    in 29s     \n",
            "\n",
            "2023-05-23 21:03:26 (132 MB/s) - ‘cc.bn.300.bin.gz.1’ saved [3934298272/3934298272]\n",
            "\n",
            "gzip: cc.bn.300.bin already exists; do you wish to overwrite (y or n)? ^C\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.bn.300.bin.gz\n",
        "!gunzip cc.bn.300.bin.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmeZnj_9P471",
        "outputId": "1fb0f545-ea1f-4b03-db0a-17e2025ac9a6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: ফ্রান্সকে হারিয়ে ২০২২ ফিফা বিশ্বকাপ জিতে নিল আর্জেন্টিনা - Cluster: 0\n",
            "Sentence: রাজশাহীর বাঘায় তিন দিনব্যাপী কৃষিপ্রযুক্তি মেলা শুরু হয়েছে - Cluster: 1\n",
            "Sentence: বিশ্ব ক্রিকেট চ্যাম্পিয়ন ইংল্যান্ডকে ১৬ রানে হারালো বাংলাদেশ ক্রিকেট দল - Cluster: 0\n",
            "Sentence: আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ৭ মিলিমিটার বৃষ্টি হয় - Cluster: 2\n",
            "Sentence: রাজধানীতে আজ সারা দিন থেমে থেমে বৃষ্টি চলতে পারে বলে আবহাওয়া অধিদপ্তর পূর্বাভাস দিয়েছে - Cluster: 1\n",
            "Sentence: এবারের ঘূর্ণিঝড়ে আট বর্গকিলোমিটার আয়তনের এই দ্বীপে দুই হাজারের বেশি ঘরবাড়ি ও দোকানপাট ক্ষতিগ্রস্ত হয়েছে - Cluster: 1\n",
            "Sentence: আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ঢাকাতে ৭ মিলিমিটার বৃষ্টি হয়। - Cluster: 2\n",
            "Sentence: আগামী ১৮ মার্চ আয়ারল্যান্ডের বিপক্ষে সিরিজ খেলবে বাংলাদেশ - Cluster: 0\n",
            "Sentence: অন্যান্য বছরের চেয়ে এ মৌসুমে আরও বেশি আম রপ্তানি করা হবে - Cluster: 1\n",
            "Sentence: পৃথিবীতে গত তিন বছরে কৃষি খাতে যারা ভালো করেছে, তাদের মধ্যে রয়েছে বাংলাদেশ - Cluster: 1\n"
          ]
        }
      ],
      "source": [
        "import fasttext\n",
        "from sklearn.cluster import KMeans\n",
        "import fasttext.util\n",
        "import numpy as np\n",
        "\n",
        "# Load the FastText model\n",
        "# model = fasttext.load_model('cc.bn.300.bin')\n",
        "\n",
        "fasttext.util.download_model('bn', if_exists='ignore')\n",
        "\n",
        "\n",
        "model_path = 'cc.bn.300.bin'\n",
        "model = fasttext.load_model(model_path)\n",
        "\n",
        "sentences = [\n",
        "    'ফ্রান্সকে হারিয়ে ২০২২ ফিফা বিশ্বকাপ জিতে নিল আর্জেন্টিনা',\n",
        "    'রাজশাহীর বাঘায় তিন দিনব্যাপী কৃষিপ্রযুক্তি মেলা শুরু হয়েছে',\n",
        "    'বিশ্ব ক্রিকেট চ্যাম্পিয়ন ইংল্যান্ডকে ১৬ রানে হারালো বাংলাদেশ ক্রিকেট দল',\n",
        "    'আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ৭ মিলিমিটার বৃষ্টি হয়',\n",
        "    'রাজধানীতে আজ সারা দিন থেমে থেমে বৃষ্টি চলতে পারে বলে আবহাওয়া অধিদপ্তর পূর্বাভাস দিয়েছে',\n",
        "    'এবারের ঘূর্ণিঝড়ে আট বর্গকিলোমিটার আয়তনের এই দ্বীপে দুই হাজারের বেশি ঘরবাড়ি ও দোকানপাট ক্ষতিগ্রস্ত হয়েছে',\n",
        "    'আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ঢাকাতে ৭ মিলিমিটার বৃষ্টি হয়।',\n",
        "    'আগামী ১৮ মার্চ আয়ারল্যান্ডের বিপক্ষে সিরিজ খেলবে বাংলাদেশ',\n",
        "    'অন্যান্য বছরের চেয়ে এ মৌসুমে আরও বেশি আম রপ্তানি করা হবে',\n",
        "    'পৃথিবীতে গত তিন বছরে কৃষি খাতে যারা ভালো করেছে, তাদের মধ্যে রয়েছে বাংলাদেশ'\n",
        "]\n",
        "\n",
        "sentence_embeddings = []\n",
        "for sentence in sentences:\n",
        "    embedding = model.get_sentence_vector(sentence)\n",
        "    sentence_embeddings.append(embedding)\n",
        "\n",
        "sentence_embeddings = np.array(sentence_embeddings)\n",
        "\n",
        "num_clusters = 3  # Number of clusters\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(sentence_embeddings)\n",
        "cluster_labels_ft = kmeans.labels_\n",
        "\n",
        "output_ft = []\n",
        "for sentence, label in zip(sentences, cluster_labels_ft):\n",
        "    print(f'Sentence: {sentence} - Cluster: {label}')\n",
        "    output_ft.append(label)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlZ-vR4KRlyG",
        "outputId": "d7939caa-1f2d-495e-89b7-34575e7f9bc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have the ground truth labels for the sentences\n",
        "true_labels = [0, 1, 0, 2, 2, 2, 2, 0, 1, 1]  # Replace with your true labels\n",
        "\n",
        "# Assuming you have the cluster labels predicted by KMeans\n",
        "predicted_labels = output_ft  # Replace with your predicted labels\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKQ2O3w_ahTx",
        "outputId": "648d6aab-de19-407d-c53c-d9ef43d0210e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.7916666666666666\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# True labels (ground truth)\n",
        "true_labels = [0, 1, 0, 2, 2, 2, 2, 0, 1, 1]\n",
        "\n",
        "# Predicted labels (cluster assignments)\n",
        "predicted_labels = cluster_labels_ft\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEQFKz7KZjoq"
      },
      "source": [
        "# Kmeans+word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1uydE6SZ5P0",
        "outputId": "dd9191f0-4ba9-4b37-ec16-abb376896627"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: ফ্রান্সকে হারিয়ে ২০২২ ফিফা বিশ্বকাপ জিতে নিল আর্জেন্টিনা - Cluster: 1\n",
            "Sentence: রাজশাহীর বাঘায় তিন দিনব্যাপী কৃষিপ্রযুক্তি মেলা শুরু হয়েছে - Cluster: 3\n",
            "Sentence: বিশ্ব ক্রিকেট চ্যাম্পিয়ন ইংল্যান্ডকে ১৬ রানে হারালো বাংলাদেশ ক্রিকেট দল - Cluster: 2\n",
            "Sentence: আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ৭ মিলিমিটার বৃষ্টি হয় - Cluster: 1\n",
            "Sentence: রাজধানীতে আজ সারা দিন থেমে থেমে বৃষ্টি চলতে পারে বলে আবহাওয়া অধিদপ্তর পূর্বাভাস দিয়েছে - Cluster: 1\n",
            "Sentence: এবারের ঘূর্ণিঝড়ে আট বর্গকিলোমিটার আয়তনের এই দ্বীপে দুই হাজারের বেশি ঘরবাড়ি ও দোকানপাট ক্ষতিগ্রস্ত হয়েছে - Cluster: 1\n",
            "Sentence: আগামী ১৮ মার্চ আয়ারল্যান্ডের বিপক্ষে সিরিজ খেলবে বাংলাদেশ - Cluster: 0\n",
            "Sentence: অন্যান্য বছরের চেয়ে এ মৌসুমে আরও বেশি আম রপ্তানি করা হবে - Cluster: 1\n",
            "Sentence: পৃথিবীতে গত তিন বছরে কৃষি খাতে যারা ভালো করেছে, তাদের মধ্যে রয়েছে বাংলাদেশ - Cluster: 1\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# Example Bengali sentences\n",
        "sentences = [\n",
        "    'ফ্রান্সকে হারিয়ে ২০২২ ফিফা বিশ্বকাপ জিতে নিল আর্জেন্টিনা',\n",
        "    'রাজশাহীর বাঘায় তিন দিনব্যাপী কৃষিপ্রযুক্তি মেলা শুরু হয়েছে',\n",
        "    'বিশ্ব ক্রিকেট চ্যাম্পিয়ন ইংল্যান্ডকে ১৬ রানে হারালো বাংলাদেশ ক্রিকেট দল',\n",
        "    'আজ সকাল ছয়টা থেকে নয়টা পর্যন্ত রাজধানী ৭ মিলিমিটার বৃষ্টি হয়',\n",
        "    'রাজধানীতে আজ সারা দিন থেমে থেমে বৃষ্টি চলতে পারে বলে আবহাওয়া অধিদপ্তর পূর্বাভাস দিয়েছে',\n",
        "    'এবারের ঘূর্ণিঝড়ে আট বর্গকিলোমিটার আয়তনের এই দ্বীপে দুই হাজারের বেশি ঘরবাড়ি ও দোকানপাট ক্ষতিগ্রস্ত হয়েছে',\n",
        "    'আগামী ১৮ মার্চ আয়ারল্যান্ডের বিপক্ষে সিরিজ খেলবে বাংলাদেশ',\n",
        "    'অন্যান্য বছরের চেয়ে এ মৌসুমে আরও বেশি আম রপ্তানি করা হবে',\n",
        "    'পৃথিবীতে গত তিন বছরে কৃষি খাতে যারা ভালো করেছে, তাদের মধ্যে রয়েছে বাংলাদেশ'\n",
        "]\n",
        "\n",
        "# Tokenize the sentences\n",
        "tokenized_sentences = [sentence.split() for sentence in sentences]\n",
        "\n",
        "# Train the Word2Vec model\n",
        "model = Word2Vec(tokenized_sentences, vector_size=300, window=5, min_count=1, sg=1)\n",
        "\n",
        "# Get sentence embeddings\n",
        "sentence_embeddings = []\n",
        "for tokenized_sentence in tokenized_sentences:\n",
        "    word_embeddings = [model.wv[word] for word in tokenized_sentence if word in model.wv]\n",
        "    if word_embeddings:\n",
        "        sentence_embedding = np.mean(word_embeddings, axis=0)\n",
        "        sentence_embeddings.append(sentence_embedding)\n",
        "\n",
        "sentence_embeddings = np.array(sentence_embeddings)\n",
        "\n",
        "# Apply k-means++ clustering\n",
        "num_clusters = 4  # Number of clusters\n",
        "kmeans = KMeans(n_clusters=num_clusters, init='k-means++', random_state=42)\n",
        "kmeans.fit(sentence_embeddings)\n",
        "\n",
        "# Get cluster assignments for each sentence\n",
        "cluster_labels_w2v = kmeans.labels_\n",
        "\n",
        "output_w2v = []\n",
        "# Print the cluster assignments\n",
        "for sentence, label in zip(sentences, cluster_labels_w2v):\n",
        "    print(f'Sentence: {sentence} - Cluster: {label}')\n",
        "    output_w2v.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OcF7RPEbTYY",
        "outputId": "6d2db007-f0b1-47c2-c775-ac69a15f05f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.2222222222222222\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming you have the ground truth labels for the sentences\n",
        "true_labels = [1, 3, 1, 0, 0, 0, 1, 3, 3]  # Replace with your true labels\n",
        "\n",
        "# Assuming you have the cluster labels predicted by KMeans\n",
        "predicted_labels = output_w2v  # Replace with your predicted labels\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlHRXY_MenOC",
        "outputId": "5f6cdf62-20ca-439f-87c5-1d6c80f518e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.24074074074074073\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# True labels (ground truth)\n",
        "true_labels = [1, 3, 1, 0, 0, 0, 1, 3, 3]\n",
        "\n",
        "# Predicted labels (cluster assignments)\n",
        "predicted_labels = cluster_labels_w2v\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CSE buet model"
      ],
      "metadata": {
        "id": "5tkJLs-zm1je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load BanglaBERT model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglabert\")\n",
        "model = AutoModel.from_pretrained(\"csebuetnlp/banglabert\")\n",
        "\n",
        "# Function to get embeddings\n",
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "# Read the CSV file\n",
        "input_file = \"/content/drive/MyDrive/Thesis Personal/Data set/Bangla Input topics.csv\"\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Extract sentences from the 'Input Text' column\n",
        "sentences = df['Input Text'].tolist()\n",
        "\n",
        "# Generate sentence embeddings\n",
        "sentence_embeddings = np.array([get_embedding(sentence) for sentence in sentences])\n",
        "\n",
        "# Perform K-means clustering\n",
        "num_clusters = 2  # Number of clusters\n",
        "kmeans = KMeans(n_clusters=num_clusters, init='k-means++', random_state=42)\n",
        "kmeans.fit(sentence_embeddings)\n",
        "\n",
        "# Get cluster labels\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "# Add predicted labels to the DataFrame\n",
        "df['Predicted Label'] = cluster_labels\n",
        "\n",
        "# Add remarks column by comparing 'Label' and 'Predicted Label'\n",
        "df['Remarks'] = df.apply(lambda row: 'Yes' if row['Label'] == row['Predicted Label'] else 'No', axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (df['Remarks'] == 'Yes').mean()\n",
        "yes_percentage = (df['Remarks'] == 'Yes').mean()\n",
        "no_percentage = (df['Remarks'] == 'No').mean()\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(df['Label'], df['Predicted Label'], average='weighted')\n",
        "recall = recall_score(df['Label'], df['Predicted Label'], average='weighted')\n",
        "f1 = f1_score(df['Label'], df['Predicted Label'], average='weighted')\n",
        "\n",
        "# Add Metrics column\n",
        "df['Metrics'] = ''\n",
        "df.at[0, 'Metrics'] = f\"Overall Accuracy: {accuracy:.2%}\\nYes: {yes_percentage:.2%}\\nNo: {no_percentage:.2%}\\n\"\n",
        "df.at[1, 'Metrics'] = f\"Precision: {precision:.2%}\\nRecall: {recall:.2%}\\nF1 Score: {f1:.2%}\"\n",
        "\n",
        "# Reorder columns\n",
        "column_order = ['Input Text', 'Label', 'Predicted Label', 'Remarks', 'Metrics']\n",
        "df = df[column_order]\n",
        "\n",
        "# Save the updated DataFrame\n",
        "output_file = \"/content/drive/MyDrive/Thesis Personal/Data set/output_file_BuetBanglaBERT_K2.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Predictions completed and saved to '{output_file}'\")\n",
        "\n",
        "# Display the first few rows of the updated DataFrame\n",
        "print(df.head())\n",
        "\n",
        "# Display clustering results\n",
        "for sentence, label in zip(sentences, cluster_labels):\n",
        "    print(f'Sentence: {sentence} - Cluster: {label}')\n",
        "\n",
        "# Display a summary of the predicted labels and remarks\n",
        "print(\"\\nPredicted Label Distribution:\")\n",
        "print(df['Predicted Label'].value_counts())\n",
        "print(\"\\nRemarks Distribution:\")\n",
        "print(df['Remarks'].value_counts(normalize=True))\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"\\nAccuracy: {accuracy:.2%}\")\n",
        "print(f\"Precision: {precision:.2%}\")\n",
        "print(f\"Recall: {recall:.2%}\")\n",
        "print(f\"F1 Score: {f1:.2%}\")\n",
        "\n",
        "# Print the output and size\n",
        "output_test2 = cluster_labels.tolist()\n",
        "print(output_test2)\n",
        "size = len(output_test2)\n",
        "print(size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYWIqSIdnCwZ",
        "outputId": "07d0eeae-c165-4b1d-ec53-91eb0a93b29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions completed and saved to '/content/drive/MyDrive/Thesis Personal/Data set/output_file_BuetBanglaBERT_K2.csv'\n",
            "                                          Input Text  Label  Predicted Label  \\\n",
            "0  সম্প্রতি বিশ্ববিদ্যালয় শাখা ছাত্রলীগের সাধারণ...      0                0   \n",
            "1  এসব অভিযোগের ব্যাপারে ছাত্রলীগের কেন্দ্রীয় সং...      0                0   \n",
            "2  বিভিন্ন সময়ে শাখা ছাত্রলীগের একাধিক সহসভাপতির...      0                0   \n",
            "3  রাজধানীর পলাশী এলাকায় ফাস্টফুডের দোকানের এক কর...      0                0   \n",
            "4  নূর উদ্দিন আহমেদ ঢাকা বিশ্ববিদ্যালয় শাখা ছাত্র...      0                0   \n",
            "\n",
            "  Remarks                                            Metrics  \n",
            "0     Yes  Overall Accuracy: 41.67%\\nYes: 41.67%\\nNo: 58....  \n",
            "1     Yes  Precision: 22.23%\\nRecall: 41.67%\\nF1 Score: 2...  \n",
            "2     Yes                                                     \n",
            "3     Yes                                                     \n",
            "4     Yes                                                     \n",
            "Sentence: সম্প্রতি বিশ্ববিদ্যালয় শাখা ছাত্রলীগের সাধারণ সম্পাদকের বিরুদ্ধে মেডিকেল প্রশ্নপত্র ফাঁসের অভিযোগ উঠেছে - Cluster: 0\n",
            "Sentence: এসব অভিযোগের ব্যাপারে ছাত্রলীগের কেন্দ্রীয় সংসদের যুগ্ম সাধারণ সম্পাদক ও তদন্ত কমিটির সদস্য আবদুল্লাহ হীল প্রথম আলোকে বলেন, তাঁরা সব বিষয়ে তদন্ত করবেন - Cluster: 0\n",
            "Sentence: বিভিন্ন সময়ে শাখা ছাত্রলীগের একাধিক সহসভাপতির বিরুদ্ধে চাঁদাবাজি, মারধর এবং ছাত্রদলের সঙ্গে সংশ্লিষ্ট থাকার অভিযোগ উঠেছে - Cluster: 0\n",
            "Sentence: রাজধানীর পলাশী এলাকায় ফাস্টফুডের দোকানের এক কর্মচারীকে মারধরের অভিযোগ উঠেছে ঢাকা বিশ্ববিদ্যালয় শাখা ছাত্রলীগের এক নেতার বিরুদ্ধে - Cluster: 0\n",
            "Sentence: নূর উদ্দিন আহমেদ ঢাকা বিশ্ববিদ্যালয় শাখা ছাত্রলীগের সাধারণ সম্পাদক তানভীর হাসান সৈকতের অনুসারী হিসেবে পরিচিত - Cluster: 0\n",
            "Sentence: রাজধানীর মিরপুরের বোটানিক্যাল গার্ডেন, পুরান ঢাকার বলধা গার্ডেনসহ দেশের ছয়টি উদ্যান ও ইকোপার্কে প্রবেশমূল্য বাড়ানোর সিদ্ধান্তকে অন্যায্য ও অবিবেচনাপ্রসূত আখ্যায়িত করে তা কমানোর দাবি জানিয়েছে ইনস্টিটিউট ফর প্ল্যানিং অ্যান্ড ডেভেলপমেন্ট - Cluster: 1\n",
            "Sentence: ১১৯ মিনিটে বদলি মেরিনোর গোল, জার্মানির হৃদয় ভেঙে সেমিফাইনালে স্পেন - Cluster: 1\n",
            "Sentence: কোয়ার্টার ফাইনাল থেকে বিদায়ের মধ্যে দিয়ে জার্মান তারকা টনি ক্রুসের বর্ণাঢ্য ফুটবল ক্যারিয়ারেরও হতাশজনক সমাপ্তি ঘটল - Cluster: 1\n",
            "Sentence: নয়তো স্লোভেনিয়ার বিপক্ষে ১০৫ মিনিটে পেনাল্টি মিস করে কি আর শিশুদের মতো কাঁদেন - Cluster: 1\n",
            "Sentence: এখনো গোল করার প্রতিটি সুযোগ লুফে নিতে চান রোনালদো - Cluster: 0\n",
            "Sentence: তবে ইউরোর শেষ ষোলোয় পেনাল্টি মিস ও ফ্রি–কিকে একের পর এক সুযোগ হাতছাড়া করার কারণে বেশ সমালোচনার মুখে পড়েছেন রোনালদো - Cluster: 1\n",
            "Sentence: যে কারণে আজ ফ্রান্সের বিপক্ষে ম্যাচের আগে কোচ রবার্তো মার্তিনেজকেও বিষয়টি নিয়ে কথা বলতে হয়েছে - Cluster: 1\n",
            "Sentence: ক্যারিয়ারে এখন পর্যন্ত ফ্রি–কিক থেকে ৬৩টি গোল করেছেন আল নাসর তারকা - Cluster: 1\n",
            "Sentence: বাংলাদেশ উদ্বেগজনক মাত্রার দূষণ এবং পরিবেশগত স্বাস্থ্য ঝুঁকিতে রয়েছে যা তুলনামূলক বেশি ক্ষতি করছে দরিদ্র, পাঁচ বছরের কম শিশু, বয়স্ক এবং নারীদের, যা বিশ্বব্যাংকের এক নতুন প্রতিবেদনে বলা হয়েছে - Cluster: 1\n",
            "Sentence: বাংলাদেশের জন্য পরিবেশের ঝুঁকি মোকাবেলা একই সঙ্গে উন্নয়ন ও অর্থনৈতিক অগ্রাধিকার - Cluster: 1\n",
            "Sentence: পরিবেশ দূষণ শিশুদের ওপর মারাত্বক প্রভাব ফেলছে - Cluster: 0\n",
            "Sentence: বায়ু দূষণ নিয়ন্ত্রণে সময়মতো এবং জরুরি হস্তক্ষেপ, উন্নত পানি, স্যানিটেশন ও হাইজিন (ওয়াশ) এবং সীসা দূষণ নিয়ন্ত্রণ প্রতি বছর ১ লাখ ৩৩ হাজারের বেশি অকালমৃত্যু ঠেকাতে পারে - Cluster: 1\n",
            "Sentence: সবুজ বিদ্যুৎ উৎপাদনে বিনিয়োগ,রান্নায় সবুজ জ্বালানি ব্যবহার এবং শিল্প-কারখানা থেকে দূষণ রোধে কঠোর নিয়ন্ত্রণ বায়ু দূষণ কমাতে পারে - Cluster: 1\n",
            "Sentence: সদ্য বিদায়ী ২০২৩-২৪ অর্থবছরের প্রথম ১০ মাস ও এর আগের ২০২২-২৩ অর্থবছরের প্রথম ১০ মাস মিলিয়ে মোট ২০ মাসে ৯ হাজার ৩১৪ কোটি ডলারের রপ্তানির তথ্য দিয়েছিল রপ্তানি উন্নয়ন ব্যুরো (ইপিবি) - Cluster: 1\n",
            "Sentence: তবে বাংলাদেশ ব্যাংক এখন বলছে, ওই সময় রপ্তানি হয়েছে ৬ হাজার ৯৮০ কোটি ডলার। তার মানে ২৫ শতাংশ রপ্তানির তথ্য উধাও হয়ে গেছে - Cluster: 1\n",
            "Sentence: প্তানির হিসাব দেশের লেনদেন ভারসাম্য ও বৈদেশিক মুদ্রার বিনিময় হারে প্রভাব ফেলে - Cluster: 1\n",
            "Sentence: এদিকে পণ্য রপ্তানির ২ হাজার ৩৩৪ কোটি ডলারের হিসাব কোথায় গেল, সে বিষয়ে নিশ্চুপ আছেন ইপিবির কর্মকর্তারা - Cluster: 1\n",
            "Sentence: রপ্তানির প্রকৃত তথ্যের ভিত্তিতে কেন্দ্রীয় ব্যাংক গত বুধবার লেনদেন ভারসাম্যের হিসাব করেছে - Cluster: 1\n",
            "Sentence: রপ্তানি তথ্যের হিসাবে ওলটপালট হওয়ায় গত বছরের জুলাই থেকে চলতি বছরের এপ্রিল পর্যন্ত লেনদেন ভারসাম্যে ঘাটতি হয়েছে ৫৫৬ কোটি ডলার - Cluster: 1\n",
            "\n",
            "Predicted Label Distribution:\n",
            "Predicted Label\n",
            "1    17\n",
            "0     7\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Remarks Distribution:\n",
            "Remarks\n",
            "No     0.583333\n",
            "Yes    0.416667\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Accuracy: 41.67%\n",
            "Precision: 22.23%\n",
            "Recall: 41.67%\n",
            "F1 Score: 28.23%\n",
            "[0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LfYmT33MNrTR",
        "SQmqx8ixEcyl",
        "rWI1IE-THh5p"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}